Understand that this is a work in progress and changes to code must be limited to those requested.  Architecture must be respected.

Currently the LLM prompts and possible LLM config parameters are to be adjusted so that the transcript_postprocessed output 
resembles the desired_output better and without the injected error text as is now present.
