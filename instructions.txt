
Current status:   

While formatted_transcript is generated the content is corrected to be in coherent sentences that use periods, 
commas, and capital letters as requirementts dictate.

The purpose of the LLM is to translate a raw audio transcript into an essay format that has paragraphs and gramatically correct 
sentences. Headings where appropriate.  Paragraphs and headings are separated by a blank line.  Do not use connecting dashes.  
Connecting dashes can be replaced with a comma followed by a space or a period followed by two spaces and the capital letter of 
a new sentence as appropriate if grammar cannot make the transition with an appropriate connecting word.

Current output is not formattted.  This does not meet requirements.  I seen no capital letters or punctation 
marks or paragraphs.  They should all be there.  A file showing sample output is 'desired_output.txt'

The document is split into multiple chunks with overlap making smooth transitions in the output. Each time a chunk is 
processed a command line entry should show a new call has been made to the llm witth the chunk.  The sample transcript is several chunks 
long but current output does not show that it is.

Dignose the problem.

Current output:

python run.py
2025-06-21 19:00:38,197 - pipeline - WARNING - Potential discontinuity between chunks 0 and 1
2025-06-21 19:00:38,197 - pipeline - WARNING - Potential discontinuity between chunks 1 and 2
2025-06-21 19:00:38,197 - pipeline - WARNING - Potential discontinuity between chunks 2 and 3
2025-06-21 19:00:38,197 - pipeline - WARNING - Potential discontinuity between chunks 3 and 4
2025-06-21 19:00:38,198 - pipeline - WARNING - Potential discontinuity between chunks 4 and 5
2025-06-21 19:00:38,198 - pipeline - WARNING - Potential discontinuity between chunks 5 and 6
2025-06-21 19:00:38,198 - pipeline - WARNING - Potential discontinuity between chunks 6 and 7
2025-06-21 19:00:38,198 - pipeline - WARNING - Potential discontinuity between chunks 7 and 8
2025-06-21 19:00:38,198 - pipeline - WARNING - Potential discontinuity between chunks 8 and 9
2025-06-21 19:00:38,198 - pipeline - WARNING - Potential discontinuity between chunks 9 and 10
2025-06-21 19:00:38,198 - pipeline - WARNING - Potential discontinuity between chunks 10 and 11
2025-06-21 19:00:38,198 - pipeline - INFO - Created 12 chunks from input
2025-06-21 19:00:38,198 - pipeline - INFO - Processing chunk 1/12 (length: 791)
2025-06-21 19:00:38,198 - pipeline - INFO - Making LLM API call #1
2025-06-21 19:00:38,359 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:38,359 - pipeline - INFO - Processing chunk 2/12 (length: 796)
2025-06-21 19:00:38,359 - pipeline - INFO - Making LLM API call #2
2025-06-21 19:00:38,509 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:38,509 - pipeline - INFO - Processing chunk 3/12 (length: 798)
2025-06-21 19:00:38,509 - pipeline - INFO - Making LLM API call #3
2025-06-21 19:00:38,660 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:38,660 - pipeline - INFO - Processing chunk 4/12 (length: 798)
2025-06-21 19:00:38,660 - pipeline - INFO - Making LLM API call #4
2025-06-21 19:00:38,811 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:38,812 - pipeline - INFO - Processing chunk 5/12 (length: 795)
2025-06-21 19:00:38,812 - pipeline - INFO - Making LLM API call #5
2025-06-21 19:00:38,962 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:38,962 - pipeline - INFO - Processing chunk 6/12 (length: 797)
2025-06-21 19:00:38,962 - pipeline - INFO - Making LLM API call #6
2025-06-21 19:00:39,111 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:39,111 - pipeline - INFO - Processing chunk 7/12 (length: 797)
2025-06-21 19:00:39,111 - pipeline - INFO - Making LLM API call #7
2025-06-21 19:00:39,261 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:39,261 - pipeline - INFO - Processing chunk 8/12 (length: 797)
2025-06-21 19:00:39,261 - pipeline - INFO - Making LLM API call #8
2025-06-21 19:00:39,411 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:39,411 - pipeline - INFO - Processing chunk 9/12 (length: 797)
2025-06-21 19:00:39,411 - pipeline - INFO - Making LLM API call #9
2025-06-21 19:00:39,563 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:39,563 - pipeline - INFO - Processing chunk 10/12 (length: 793)
2025-06-21 19:00:39,563 - pipeline - INFO - Making LLM API call #10
2025-06-21 19:00:39,712 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:39,713 - pipeline - INFO - Processing chunk 11/12 (length: 797)
2025-06-21 19:00:39,713 - pipeline - INFO - Making LLM API call #11
2025-06-21 19:00:39,862 - pipeline - WARNING - LLM returned potentially invalid formatting
2025-06-21 19:00:39,863 - pipeline - INFO - Processing chunk 12/12 (length: 685)
2025-06-21 19:00:39,863 - pipeline - INFO - Making LLM API call #12
2025-06-21 19:00:40,015 - pipeline - WARNING - LLM returned potentially invalid formatting
Successfully created formatted_transcript.txt
(venv) kdog@kdogsputer:~/Desktop/temp/process transcript$ 


Currently the output file is blank.


Design :

Transistions are smooth because the chumking connects already formatted sections as it builds output.  
Overlap where fresh lines are added supplies a leading edge of formated overlap so the chunk being 
formatted can be made to ttransition correct so that the connection is later correct.

example.  If a chunk is 1000 characters long the second chunnk would begin at 800 characters so the 
first 200 characters are formattted with previous content.  This overlap allows the overlap to be 
rewritten when the second chunk overwrites the tail of the first chunk.

The end of the second chunk is at 1800 so the third chunk begins at 1600 to repeat the overlap 
re-write process until a smooth translation of the entire file has been accomplished.

This should be a common technique to process a translation in chunks and the web should be 
consulted as needed to ensure logic is correct.

Chunking will have to be along word boundaries because of the nature of the continuous transcript.   

The overlap is intended to fix problems with chunking in the middle of a sentence or paragraph.
