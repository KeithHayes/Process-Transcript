{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1166.7164179104477,
  "eval_steps": 500,
  "global_step": 10500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 2.2388059701492535,
      "grad_norm": 1.7392425537109375,
      "learning_rate": 2.4999809085748925e-05,
      "loss": 0.8773,
      "step": 20
    },
    {
      "epoch": 4.477611940298507,
      "grad_norm": 1.357404112815857,
      "learning_rate": 2.4999195628252878e-05,
      "loss": 0.7223,
      "step": 40
    },
    {
      "epoch": 6.7164179104477615,
      "grad_norm": 1.1564737558364868,
      "learning_rate": 2.499815911942543e-05,
      "loss": 0.6176,
      "step": 60
    },
    {
      "epoch": 8.955223880597014,
      "grad_norm": 2.577207088470459,
      "learning_rate": 2.499669959434855e-05,
      "loss": 0.557,
      "step": 80
    },
    {
      "epoch": 11.119402985074627,
      "grad_norm": 2.026858329772949,
      "learning_rate": 2.4994817102421747e-05,
      "loss": 0.4957,
      "step": 100
    },
    {
      "epoch": 13.35820895522388,
      "grad_norm": 2.085632562637329,
      "learning_rate": 2.4992511707360374e-05,
      "loss": 0.4917,
      "step": 120
    },
    {
      "epoch": 15.597014925373134,
      "grad_norm": 2.7572178840637207,
      "learning_rate": 2.498978348719349e-05,
      "loss": 0.3088,
      "step": 140
    },
    {
      "epoch": 17.83582089552239,
      "grad_norm": 1.9578242301940918,
      "learning_rate": 2.498663253426121e-05,
      "loss": 0.2922,
      "step": 160
    },
    {
      "epoch": 20.0,
      "grad_norm": 7.603149890899658,
      "learning_rate": 2.498305895521158e-05,
      "loss": 0.2759,
      "step": 180
    },
    {
      "epoch": 22.238805970149254,
      "grad_norm": 2.4958877563476562,
      "learning_rate": 2.4979062870996982e-05,
      "loss": 0.2068,
      "step": 200
    },
    {
      "epoch": 24.47761194029851,
      "grad_norm": 3.2319753170013428,
      "learning_rate": 2.497464441687001e-05,
      "loss": 0.1693,
      "step": 220
    },
    {
      "epoch": 26.71641791044776,
      "grad_norm": 4.142152786254883,
      "learning_rate": 2.496980374237892e-05,
      "loss": 0.129,
      "step": 240
    },
    {
      "epoch": 28.955223880597014,
      "grad_norm": 0.2347509115934372,
      "learning_rate": 2.4964541011362568e-05,
      "loss": 0.0787,
      "step": 260
    },
    {
      "epoch": 31.119402985074625,
      "grad_norm": 2.266855239868164,
      "learning_rate": 2.4958856401944837e-05,
      "loss": 0.0515,
      "step": 280
    },
    {
      "epoch": 33.35820895522388,
      "grad_norm": 4.464694023132324,
      "learning_rate": 2.4952750106528636e-05,
      "loss": 0.0403,
      "step": 300
    },
    {
      "epoch": 35.59701492537313,
      "grad_norm": 4.864621639251709,
      "learning_rate": 2.4946222331789377e-05,
      "loss": 0.0228,
      "step": 320
    },
    {
      "epoch": 37.83582089552239,
      "grad_norm": 3.1868574619293213,
      "learning_rate": 2.493927329866798e-05,
      "loss": 0.0142,
      "step": 340
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.7177754044532776,
      "learning_rate": 2.49319032423634e-05,
      "loss": 0.0095,
      "step": 360
    },
    {
      "epoch": 42.23880597014925,
      "grad_norm": 0.5689896941184998,
      "learning_rate": 2.4924112412324658e-05,
      "loss": 0.0064,
      "step": 380
    },
    {
      "epoch": 44.47761194029851,
      "grad_norm": 1.0360682010650635,
      "learning_rate": 2.4915901072242402e-05,
      "loss": 0.0041,
      "step": 400
    },
    {
      "epoch": 46.71641791044776,
      "grad_norm": 0.40694475173950195,
      "learning_rate": 2.490726950003999e-05,
      "loss": 0.0039,
      "step": 420
    },
    {
      "epoch": 48.95522388059702,
      "grad_norm": 0.16450732946395874,
      "learning_rate": 2.4898217987864065e-05,
      "loss": 0.004,
      "step": 440
    },
    {
      "epoch": 51.11940298507463,
      "grad_norm": 0.3679637908935547,
      "learning_rate": 2.4888746842074688e-05,
      "loss": 0.0026,
      "step": 460
    },
    {
      "epoch": 53.35820895522388,
      "grad_norm": 0.05079720914363861,
      "learning_rate": 2.487885638323495e-05,
      "loss": 0.0017,
      "step": 480
    },
    {
      "epoch": 55.59701492537313,
      "grad_norm": 0.06643065810203552,
      "learning_rate": 2.4868546946100135e-05,
      "loss": 0.0014,
      "step": 500
    },
    {
      "epoch": 57.83582089552239,
      "grad_norm": 0.0575651079416275,
      "learning_rate": 2.4857818879606386e-05,
      "loss": 0.0011,
      "step": 520
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.11325077712535858,
      "learning_rate": 2.4846672546858898e-05,
      "loss": 0.001,
      "step": 540
    },
    {
      "epoch": 62.23880597014925,
      "grad_norm": 0.02495221607387066,
      "learning_rate": 2.4835108325119615e-05,
      "loss": 0.001,
      "step": 560
    },
    {
      "epoch": 64.4776119402985,
      "grad_norm": 0.06739053875207901,
      "learning_rate": 2.4823126605794485e-05,
      "loss": 0.0008,
      "step": 580
    },
    {
      "epoch": 66.71641791044776,
      "grad_norm": 0.027869122102856636,
      "learning_rate": 2.4810727794420173e-05,
      "loss": 0.0008,
      "step": 600
    },
    {
      "epoch": 68.95522388059702,
      "grad_norm": 0.0330987386405468,
      "learning_rate": 2.479791231065039e-05,
      "loss": 0.0007,
      "step": 620
    },
    {
      "epoch": 71.11940298507463,
      "grad_norm": 0.021351058036088943,
      "learning_rate": 2.4784680588241643e-05,
      "loss": 0.0007,
      "step": 640
    },
    {
      "epoch": 73.35820895522389,
      "grad_norm": 0.013016710057854652,
      "learning_rate": 2.4771033075038568e-05,
      "loss": 0.0006,
      "step": 660
    },
    {
      "epoch": 75.59701492537313,
      "grad_norm": 0.03303837403655052,
      "learning_rate": 2.475697023295879e-05,
      "loss": 0.0006,
      "step": 680
    },
    {
      "epoch": 77.83582089552239,
      "grad_norm": 0.03763160482048988,
      "learning_rate": 2.4742492537977253e-05,
      "loss": 0.0006,
      "step": 700
    },
    {
      "epoch": 80.0,
      "grad_norm": 0.008825949393212795,
      "learning_rate": 2.4727600480110143e-05,
      "loss": 0.0005,
      "step": 720
    },
    {
      "epoch": 82.23880597014926,
      "grad_norm": 0.018640853464603424,
      "learning_rate": 2.471229456339829e-05,
      "loss": 0.0005,
      "step": 740
    },
    {
      "epoch": 84.4776119402985,
      "grad_norm": 0.028157202526926994,
      "learning_rate": 2.4696575305890108e-05,
      "loss": 0.0005,
      "step": 760
    },
    {
      "epoch": 86.71641791044776,
      "grad_norm": 0.013683509081602097,
      "learning_rate": 2.468044323962405e-05,
      "loss": 0.0005,
      "step": 780
    },
    {
      "epoch": 88.95522388059702,
      "grad_norm": 0.008811719715595245,
      "learning_rate": 2.4663898910610628e-05,
      "loss": 0.0004,
      "step": 800
    },
    {
      "epoch": 91.11940298507463,
      "grad_norm": 0.03434302657842636,
      "learning_rate": 2.464694287881391e-05,
      "loss": 0.0004,
      "step": 820
    },
    {
      "epoch": 93.35820895522389,
      "grad_norm": 0.008265920914709568,
      "learning_rate": 2.4629575718132565e-05,
      "loss": 0.0004,
      "step": 840
    },
    {
      "epoch": 95.59701492537313,
      "grad_norm": 0.013254933059215546,
      "learning_rate": 2.461179801638046e-05,
      "loss": 0.0004,
      "step": 860
    },
    {
      "epoch": 97.83582089552239,
      "grad_norm": 0.01761801354587078,
      "learning_rate": 2.4593610375266745e-05,
      "loss": 0.0004,
      "step": 880
    },
    {
      "epoch": 100.0,
      "grad_norm": 0.010200216434895992,
      "learning_rate": 2.4575013410375496e-05,
      "loss": 0.0003,
      "step": 900
    },
    {
      "epoch": 102.23880597014926,
      "grad_norm": 0.005085292272269726,
      "learning_rate": 2.4556007751144876e-05,
      "loss": 0.0003,
      "step": 920
    },
    {
      "epoch": 104.4776119402985,
      "grad_norm": 0.005495924968272448,
      "learning_rate": 2.4536594040845838e-05,
      "loss": 0.0003,
      "step": 940
    },
    {
      "epoch": 106.71641791044776,
      "grad_norm": 0.020824769511818886,
      "learning_rate": 2.4516772936560344e-05,
      "loss": 0.0004,
      "step": 960
    },
    {
      "epoch": 108.95522388059702,
      "grad_norm": 0.011364161036908627,
      "learning_rate": 2.449654510915913e-05,
      "loss": 0.0003,
      "step": 980
    },
    {
      "epoch": 111.11940298507463,
      "grad_norm": 0.02281063050031662,
      "learning_rate": 2.4475911243278993e-05,
      "loss": 0.0003,
      "step": 1000
    },
    {
      "epoch": 113.35820895522389,
      "grad_norm": 0.006393761374056339,
      "learning_rate": 2.4454872037299626e-05,
      "loss": 0.0003,
      "step": 1020
    },
    {
      "epoch": 115.59701492537313,
      "grad_norm": 0.013497591018676758,
      "learning_rate": 2.443342820331999e-05,
      "loss": 0.0003,
      "step": 1040
    },
    {
      "epoch": 117.83582089552239,
      "grad_norm": 0.01809029094874859,
      "learning_rate": 2.441158046713418e-05,
      "loss": 0.0003,
      "step": 1060
    },
    {
      "epoch": 120.0,
      "grad_norm": 0.008101182989776134,
      "learning_rate": 2.43893295682069e-05,
      "loss": 0.0003,
      "step": 1080
    },
    {
      "epoch": 122.23880597014926,
      "grad_norm": 0.009206260554492474,
      "learning_rate": 2.43666762596484e-05,
      "loss": 0.0003,
      "step": 1100
    },
    {
      "epoch": 124.4776119402985,
      "grad_norm": 0.010256977751851082,
      "learning_rate": 2.434362130818901e-05,
      "loss": 0.0003,
      "step": 1120
    },
    {
      "epoch": 126.71641791044776,
      "grad_norm": 0.004478952847421169,
      "learning_rate": 2.4320165494153176e-05,
      "loss": 0.0002,
      "step": 1140
    },
    {
      "epoch": 128.955223880597,
      "grad_norm": 0.02442585863173008,
      "learning_rate": 2.4296309611433048e-05,
      "loss": 0.0003,
      "step": 1160
    },
    {
      "epoch": 131.11940298507463,
      "grad_norm": 4.323824882507324,
      "learning_rate": 2.427205446746163e-05,
      "loss": 0.0003,
      "step": 1180
    },
    {
      "epoch": 133.3582089552239,
      "grad_norm": 3.2431957721710205,
      "learning_rate": 2.4247400883185416e-05,
      "loss": 0.0101,
      "step": 1200
    },
    {
      "epoch": 135.59701492537314,
      "grad_norm": 2.3787569999694824,
      "learning_rate": 2.422234969303664e-05,
      "loss": 0.0077,
      "step": 1220
    },
    {
      "epoch": 137.83582089552237,
      "grad_norm": 4.633032321929932,
      "learning_rate": 2.419690174490501e-05,
      "loss": 0.0091,
      "step": 1240
    },
    {
      "epoch": 140.0,
      "grad_norm": 4.394322395324707,
      "learning_rate": 2.4171057900109013e-05,
      "loss": 0.0083,
      "step": 1260
    },
    {
      "epoch": 142.23880597014926,
      "grad_norm": 0.49951714277267456,
      "learning_rate": 2.414481903336678e-05,
      "loss": 0.004,
      "step": 1280
    },
    {
      "epoch": 144.47761194029852,
      "grad_norm": 0.28871068358421326,
      "learning_rate": 2.4118186032766457e-05,
      "loss": 0.0025,
      "step": 1300
    },
    {
      "epoch": 146.71641791044777,
      "grad_norm": 0.08994973450899124,
      "learning_rate": 2.409115979973616e-05,
      "loss": 0.0012,
      "step": 1320
    },
    {
      "epoch": 148.955223880597,
      "grad_norm": 0.10876202583312988,
      "learning_rate": 2.406374124901346e-05,
      "loss": 0.0016,
      "step": 1340
    },
    {
      "epoch": 151.11940298507463,
      "grad_norm": 0.0460195392370224,
      "learning_rate": 2.4035931308614428e-05,
      "loss": 0.0006,
      "step": 1360
    },
    {
      "epoch": 153.3582089552239,
      "grad_norm": 0.005510164424777031,
      "learning_rate": 2.400773091980222e-05,
      "loss": 0.0004,
      "step": 1380
    },
    {
      "epoch": 155.59701492537314,
      "grad_norm": 0.015917645767331123,
      "learning_rate": 2.3979141037055216e-05,
      "loss": 0.0004,
      "step": 1400
    },
    {
      "epoch": 157.83582089552237,
      "grad_norm": 0.008920848369598389,
      "learning_rate": 2.3950162628034723e-05,
      "loss": 0.0003,
      "step": 1420
    },
    {
      "epoch": 160.0,
      "grad_norm": 0.02078908309340477,
      "learning_rate": 2.3920796673552216e-05,
      "loss": 0.0003,
      "step": 1440
    },
    {
      "epoch": 162.23880597014926,
      "grad_norm": 0.011904861778020859,
      "learning_rate": 2.3891044167536147e-05,
      "loss": 0.0003,
      "step": 1460
    },
    {
      "epoch": 164.47761194029852,
      "grad_norm": 0.007283416576683521,
      "learning_rate": 2.38609061169983e-05,
      "loss": 0.0003,
      "step": 1480
    },
    {
      "epoch": 166.71641791044777,
      "grad_norm": 0.012210342101752758,
      "learning_rate": 2.3830383541999708e-05,
      "loss": 0.0002,
      "step": 1500
    },
    {
      "epoch": 168.955223880597,
      "grad_norm": 0.010594189167022705,
      "learning_rate": 2.3799477475616127e-05,
      "loss": 0.0002,
      "step": 1520
    },
    {
      "epoch": 171.11940298507463,
      "grad_norm": 0.005333950277417898,
      "learning_rate": 2.376818896390307e-05,
      "loss": 0.0002,
      "step": 1540
    },
    {
      "epoch": 173.3582089552239,
      "grad_norm": 0.010163195431232452,
      "learning_rate": 2.3736519065860417e-05,
      "loss": 0.0003,
      "step": 1560
    },
    {
      "epoch": 175.59701492537314,
      "grad_norm": 0.002730210078880191,
      "learning_rate": 2.3704468853396532e-05,
      "loss": 0.0002,
      "step": 1580
    },
    {
      "epoch": 177.83582089552237,
      "grad_norm": 0.004326159600168467,
      "learning_rate": 2.367203941129204e-05,
      "loss": 0.0002,
      "step": 1600
    },
    {
      "epoch": 180.0,
      "grad_norm": 0.015848433598876,
      "learning_rate": 2.3639231837163055e-05,
      "loss": 0.0002,
      "step": 1620
    },
    {
      "epoch": 182.23880597014926,
      "grad_norm": 0.004922998603433371,
      "learning_rate": 2.3606047241424074e-05,
      "loss": 0.0002,
      "step": 1640
    },
    {
      "epoch": 184.47761194029852,
      "grad_norm": 0.00872355978935957,
      "learning_rate": 2.3572486747250355e-05,
      "loss": 0.0002,
      "step": 1660
    },
    {
      "epoch": 186.71641791044777,
      "grad_norm": 0.003975980449467897,
      "learning_rate": 2.353855149053994e-05,
      "loss": 0.0002,
      "step": 1680
    },
    {
      "epoch": 188.955223880597,
      "grad_norm": 0.004473847337067127,
      "learning_rate": 2.3504242619875176e-05,
      "loss": 0.0002,
      "step": 1700
    },
    {
      "epoch": 191.11940298507463,
      "grad_norm": 0.016451915726065636,
      "learning_rate": 2.3469561296483866e-05,
      "loss": 0.0002,
      "step": 1720
    },
    {
      "epoch": 193.3582089552239,
      "grad_norm": 0.006462070159614086,
      "learning_rate": 2.3434508694199953e-05,
      "loss": 0.0002,
      "step": 1740
    },
    {
      "epoch": 195.59701492537314,
      "grad_norm": 0.007671811152249575,
      "learning_rate": 2.3399085999423776e-05,
      "loss": 0.0002,
      "step": 1760
    },
    {
      "epoch": 197.83582089552237,
      "grad_norm": 0.002433648332953453,
      "learning_rate": 2.3363294411081946e-05,
      "loss": 0.0002,
      "step": 1780
    },
    {
      "epoch": 200.0,
      "grad_norm": 0.0034628859721124172,
      "learning_rate": 2.3327135140586745e-05,
      "loss": 0.0002,
      "step": 1800
    },
    {
      "epoch": 202.23880597014926,
      "grad_norm": 0.004183480981737375,
      "learning_rate": 2.329060941179513e-05,
      "loss": 0.0002,
      "step": 1820
    },
    {
      "epoch": 204.47761194029852,
      "grad_norm": 0.0036985159385949373,
      "learning_rate": 2.325371846096731e-05,
      "loss": 0.0002,
      "step": 1840
    },
    {
      "epoch": 206.71641791044777,
      "grad_norm": 0.0052843098528683186,
      "learning_rate": 2.3216463536724903e-05,
      "loss": 0.0001,
      "step": 1860
    },
    {
      "epoch": 208.955223880597,
      "grad_norm": 0.004335763398557901,
      "learning_rate": 2.3178845900008674e-05,
      "loss": 0.0001,
      "step": 1880
    },
    {
      "epoch": 211.11940298507463,
      "grad_norm": 0.004958540201187134,
      "learning_rate": 2.3140866824035855e-05,
      "loss": 0.0002,
      "step": 1900
    },
    {
      "epoch": 213.3582089552239,
      "grad_norm": 0.0047752889804542065,
      "learning_rate": 2.310252759425706e-05,
      "loss": 0.0001,
      "step": 1920
    },
    {
      "epoch": 215.59701492537314,
      "grad_norm": 0.005637388676404953,
      "learning_rate": 2.3063829508312773e-05,
      "loss": 0.0001,
      "step": 1940
    },
    {
      "epoch": 217.83582089552237,
      "grad_norm": 0.0059898244217038155,
      "learning_rate": 2.302477387598941e-05,
      "loss": 0.0001,
      "step": 1960
    },
    {
      "epoch": 220.0,
      "grad_norm": 0.003443650435656309,
      "learning_rate": 2.298536201917502e-05,
      "loss": 0.0001,
      "step": 1980
    },
    {
      "epoch": 222.23880597014926,
      "grad_norm": 0.005070361774414778,
      "learning_rate": 2.2945595271814525e-05,
      "loss": 0.0001,
      "step": 2000
    },
    {
      "epoch": 224.47761194029852,
      "grad_norm": 0.006496877875179052,
      "learning_rate": 2.290547497986456e-05,
      "loss": 0.0001,
      "step": 2020
    },
    {
      "epoch": 226.71641791044777,
      "grad_norm": 0.0026314679998904467,
      "learning_rate": 2.2865002501247956e-05,
      "loss": 0.0001,
      "step": 2040
    },
    {
      "epoch": 228.955223880597,
      "grad_norm": 0.005729662720113993,
      "learning_rate": 2.282417920580773e-05,
      "loss": 0.0001,
      "step": 2060
    },
    {
      "epoch": 231.11940298507463,
      "grad_norm": 0.004337968770414591,
      "learning_rate": 2.278300647526075e-05,
      "loss": 0.0001,
      "step": 2080
    },
    {
      "epoch": 233.3582089552239,
      "grad_norm": 0.003453794401139021,
      "learning_rate": 2.2741485703150975e-05,
      "loss": 0.0001,
      "step": 2100
    },
    {
      "epoch": 235.59701492537314,
      "grad_norm": 0.0035228333435952663,
      "learning_rate": 2.2699618294802273e-05,
      "loss": 0.0001,
      "step": 2120
    },
    {
      "epoch": 237.83582089552237,
      "grad_norm": 0.006797152571380138,
      "learning_rate": 2.265740566727085e-05,
      "loss": 0.0001,
      "step": 2140
    },
    {
      "epoch": 240.0,
      "grad_norm": 0.003932998050004244,
      "learning_rate": 2.2614849249297314e-05,
      "loss": 0.0001,
      "step": 2160
    },
    {
      "epoch": 242.23880597014926,
      "grad_norm": 0.004110631532967091,
      "learning_rate": 2.2571950481258296e-05,
      "loss": 0.0001,
      "step": 2180
    },
    {
      "epoch": 244.47761194029852,
      "grad_norm": 0.004450931679457426,
      "learning_rate": 2.2528710815117705e-05,
      "loss": 0.0001,
      "step": 2200
    },
    {
      "epoch": 246.71641791044777,
      "grad_norm": 0.00439585791900754,
      "learning_rate": 2.2485131714377573e-05,
      "loss": 0.0001,
      "step": 2220
    },
    {
      "epoch": 248.955223880597,
      "grad_norm": 0.0037213899195194244,
      "learning_rate": 2.2441214654028558e-05,
      "loss": 0.0001,
      "step": 2240
    },
    {
      "epoch": 251.11940298507463,
      "grad_norm": 0.0028053189162164927,
      "learning_rate": 2.2396961120499967e-05,
      "loss": 0.0001,
      "step": 2260
    },
    {
      "epoch": 253.3582089552239,
      "grad_norm": 0.0038341241888701916,
      "learning_rate": 2.2352372611609494e-05,
      "loss": 0.0001,
      "step": 2280
    },
    {
      "epoch": 255.59701492537314,
      "grad_norm": 0.004445510450750589,
      "learning_rate": 2.230745063651249e-05,
      "loss": 0.0001,
      "step": 2300
    },
    {
      "epoch": 257.8358208955224,
      "grad_norm": 0.004017032217234373,
      "learning_rate": 2.226219671565091e-05,
      "loss": 0.0001,
      "step": 2320
    },
    {
      "epoch": 260.0,
      "grad_norm": 0.0014397193444892764,
      "learning_rate": 2.2216612380701838e-05,
      "loss": 0.0001,
      "step": 2340
    },
    {
      "epoch": 262.23880597014926,
      "grad_norm": 0.0037488695234060287,
      "learning_rate": 2.2170699174525635e-05,
      "loss": 0.0001,
      "step": 2360
    },
    {
      "epoch": 264.4776119402985,
      "grad_norm": 0.003664544550701976,
      "learning_rate": 2.212445865111375e-05,
      "loss": 0.0001,
      "step": 2380
    },
    {
      "epoch": 266.7164179104478,
      "grad_norm": 0.004140173550695181,
      "learning_rate": 2.207789237553608e-05,
      "loss": 0.0001,
      "step": 2400
    },
    {
      "epoch": 268.95522388059703,
      "grad_norm": 0.0022912698332220316,
      "learning_rate": 2.2031001923888054e-05,
      "loss": 0.0001,
      "step": 2420
    },
    {
      "epoch": 271.1194029850746,
      "grad_norm": 0.010338110849261284,
      "learning_rate": 2.1983788883237228e-05,
      "loss": 0.0001,
      "step": 2440
    },
    {
      "epoch": 273.35820895522386,
      "grad_norm": 0.002606084570288658,
      "learning_rate": 2.193625485156961e-05,
      "loss": 0.0001,
      "step": 2460
    },
    {
      "epoch": 275.5970149253731,
      "grad_norm": 0.0030637127347290516,
      "learning_rate": 2.1888401437735566e-05,
      "loss": 0.0001,
      "step": 2480
    },
    {
      "epoch": 277.8358208955224,
      "grad_norm": 0.004476924426853657,
      "learning_rate": 2.184023026139535e-05,
      "loss": 0.0001,
      "step": 2500
    },
    {
      "epoch": 280.0,
      "grad_norm": 0.006919232662767172,
      "learning_rate": 2.17917429529643e-05,
      "loss": 0.0001,
      "step": 2520
    },
    {
      "epoch": 282.23880597014926,
      "grad_norm": 0.004588032606989145,
      "learning_rate": 2.1742941153557655e-05,
      "loss": 0.0001,
      "step": 2540
    },
    {
      "epoch": 284.4776119402985,
      "grad_norm": 0.0023430846631526947,
      "learning_rate": 2.1693826514935005e-05,
      "loss": 0.0001,
      "step": 2560
    },
    {
      "epoch": 286.7164179104478,
      "grad_norm": 0.001656171167269349,
      "learning_rate": 2.164440069944438e-05,
      "loss": 0.0001,
      "step": 2580
    },
    {
      "epoch": 288.95522388059703,
      "grad_norm": 0.0023238123394548893,
      "learning_rate": 2.1594665379965996e-05,
      "loss": 0.0001,
      "step": 2600
    },
    {
      "epoch": 291.1194029850746,
      "grad_norm": 0.002282453468069434,
      "learning_rate": 2.1544622239855618e-05,
      "loss": 0.0001,
      "step": 2620
    },
    {
      "epoch": 293.35820895522386,
      "grad_norm": 0.0035199017729610205,
      "learning_rate": 2.1494272972887615e-05,
      "loss": 0.0001,
      "step": 2640
    },
    {
      "epoch": 295.5970149253731,
      "grad_norm": 0.0037749737966805696,
      "learning_rate": 2.144361928319759e-05,
      "loss": 0.0001,
      "step": 2660
    },
    {
      "epoch": 297.8358208955224,
      "grad_norm": 0.003116714535281062,
      "learning_rate": 2.1392662885224747e-05,
      "loss": 0.0001,
      "step": 2680
    },
    {
      "epoch": 300.0,
      "grad_norm": 0.005498343147337437,
      "learning_rate": 2.1341405503653823e-05,
      "loss": 0.0001,
      "step": 2700
    },
    {
      "epoch": 302.23880597014926,
      "grad_norm": 0.0013728807680308819,
      "learning_rate": 2.128984887335674e-05,
      "loss": 0.0001,
      "step": 2720
    },
    {
      "epoch": 304.4776119402985,
      "grad_norm": 0.0016868716338649392,
      "learning_rate": 2.1237994739333876e-05,
      "loss": 0.0001,
      "step": 2740
    },
    {
      "epoch": 306.7164179104478,
      "grad_norm": 0.0014985030284151435,
      "learning_rate": 2.1185844856655e-05,
      "loss": 0.0001,
      "step": 2760
    },
    {
      "epoch": 308.95522388059703,
      "grad_norm": 0.0022538641933351755,
      "learning_rate": 2.1133400990399887e-05,
      "loss": 0.0001,
      "step": 2780
    },
    {
      "epoch": 311.1194029850746,
      "grad_norm": 0.0020660918671637774,
      "learning_rate": 2.1080664915598548e-05,
      "loss": 0.0001,
      "step": 2800
    },
    {
      "epoch": 313.35820895522386,
      "grad_norm": 0.002462287899106741,
      "learning_rate": 2.1027638417171176e-05,
      "loss": 0.0001,
      "step": 2820
    },
    {
      "epoch": 315.5970149253731,
      "grad_norm": 0.0019739859271794558,
      "learning_rate": 2.0974323289867725e-05,
      "loss": 0.0001,
      "step": 2840
    },
    {
      "epoch": 317.8358208955224,
      "grad_norm": 0.0017328510293737054,
      "learning_rate": 2.0920721338207163e-05,
      "loss": 0.0001,
      "step": 2860
    },
    {
      "epoch": 320.0,
      "grad_norm": 0.002005019225180149,
      "learning_rate": 2.0866834376416388e-05,
      "loss": 0.0001,
      "step": 2880
    },
    {
      "epoch": 322.23880597014926,
      "grad_norm": 0.0029934956692159176,
      "learning_rate": 2.0812664228368854e-05,
      "loss": 0.0001,
      "step": 2900
    },
    {
      "epoch": 324.4776119402985,
      "grad_norm": 0.002659790450707078,
      "learning_rate": 2.0758212727522795e-05,
      "loss": 0.0001,
      "step": 2920
    },
    {
      "epoch": 326.7164179104478,
      "grad_norm": 0.001145622693002224,
      "learning_rate": 2.0703481716859207e-05,
      "loss": 0.0001,
      "step": 2940
    },
    {
      "epoch": 328.95522388059703,
      "grad_norm": 0.002733665518462658,
      "learning_rate": 2.064847304881944e-05,
      "loss": 0.0001,
      "step": 2960
    },
    {
      "epoch": 331.1194029850746,
      "grad_norm": 0.0019420086173340678,
      "learning_rate": 2.059318858524253e-05,
      "loss": 0.0001,
      "step": 2980
    },
    {
      "epoch": 333.35820895522386,
      "grad_norm": 0.0029719530139118433,
      "learning_rate": 2.0537630197302153e-05,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 335.5970149253731,
      "grad_norm": 0.002193334512412548,
      "learning_rate": 2.048179976544332e-05,
      "loss": 0.0001,
      "step": 3020
    },
    {
      "epoch": 337.8358208955224,
      "grad_norm": 0.0025259049143642187,
      "learning_rate": 2.0425699179318715e-05,
      "loss": 0.0001,
      "step": 3040
    },
    {
      "epoch": 340.0,
      "grad_norm": 0.0013439508620649576,
      "learning_rate": 2.036933033772473e-05,
      "loss": 0.0001,
      "step": 3060
    },
    {
      "epoch": 342.23880597014926,
      "grad_norm": 0.0010678630787879229,
      "learning_rate": 2.0312695148537218e-05,
      "loss": 0.0001,
      "step": 3080
    },
    {
      "epoch": 344.4776119402985,
      "grad_norm": 0.0031630094163119793,
      "learning_rate": 2.025579552864691e-05,
      "loss": 0.0001,
      "step": 3100
    },
    {
      "epoch": 346.7164179104478,
      "grad_norm": 0.0020042655523866415,
      "learning_rate": 2.0198633403894522e-05,
      "loss": 0.0001,
      "step": 3120
    },
    {
      "epoch": 348.95522388059703,
      "grad_norm": 0.0030033623334020376,
      "learning_rate": 2.014121070900559e-05,
      "loss": 0.0001,
      "step": 3140
    },
    {
      "epoch": 351.1194029850746,
      "grad_norm": 0.0008410706068389118,
      "learning_rate": 2.0083529387524998e-05,
      "loss": 0.0001,
      "step": 3160
    },
    {
      "epoch": 353.35820895522386,
      "grad_norm": 0.16392409801483154,
      "learning_rate": 2.0025591391751148e-05,
      "loss": 0.0003,
      "step": 3180
    },
    {
      "epoch": 355.5970149253731,
      "grad_norm": 0.13253265619277954,
      "learning_rate": 1.9967398682669937e-05,
      "loss": 0.0104,
      "step": 3200
    },
    {
      "epoch": 357.8358208955224,
      "grad_norm": 2.9109296798706055,
      "learning_rate": 1.990895322988835e-05,
      "loss": 0.0045,
      "step": 3220
    },
    {
      "epoch": 360.0,
      "grad_norm": 4.391639709472656,
      "learning_rate": 1.9850257011567808e-05,
      "loss": 0.0074,
      "step": 3240
    },
    {
      "epoch": 362.23880597014926,
      "grad_norm": 1.027011513710022,
      "learning_rate": 1.9791312014357223e-05,
      "loss": 0.0053,
      "step": 3260
    },
    {
      "epoch": 364.4776119402985,
      "grad_norm": 2.4064807891845703,
      "learning_rate": 1.9732120233325734e-05,
      "loss": 0.0053,
      "step": 3280
    },
    {
      "epoch": 366.7164179104478,
      "grad_norm": 0.32672393321990967,
      "learning_rate": 1.967268367189521e-05,
      "loss": 0.0039,
      "step": 3300
    },
    {
      "epoch": 368.95522388059703,
      "grad_norm": 0.13188698887825012,
      "learning_rate": 1.9613004341772405e-05,
      "loss": 0.0027,
      "step": 3320
    },
    {
      "epoch": 371.1194029850746,
      "grad_norm": 0.010326005518436432,
      "learning_rate": 1.9553084262880928e-05,
      "loss": 0.0004,
      "step": 3340
    },
    {
      "epoch": 373.35820895522386,
      "grad_norm": 0.020398959517478943,
      "learning_rate": 1.9492925463292798e-05,
      "loss": 0.0003,
      "step": 3360
    },
    {
      "epoch": 375.5970149253731,
      "grad_norm": 0.005865709390491247,
      "learning_rate": 1.9432529979159872e-05,
      "loss": 0.0002,
      "step": 3380
    },
    {
      "epoch": 377.8358208955224,
      "grad_norm": 0.005449716467410326,
      "learning_rate": 1.9371899854644884e-05,
      "loss": 0.0002,
      "step": 3400
    },
    {
      "epoch": 380.0,
      "grad_norm": 0.004637863487005234,
      "learning_rate": 1.9311037141852286e-05,
      "loss": 0.0002,
      "step": 3420
    },
    {
      "epoch": 382.23880597014926,
      "grad_norm": 0.0047682044096291065,
      "learning_rate": 1.9249943900758754e-05,
      "loss": 0.0002,
      "step": 3440
    },
    {
      "epoch": 384.4776119402985,
      "grad_norm": 0.005591575987637043,
      "learning_rate": 1.918862219914353e-05,
      "loss": 0.0002,
      "step": 3460
    },
    {
      "epoch": 386.7164179104478,
      "grad_norm": 0.005275391973555088,
      "learning_rate": 1.9127074112518357e-05,
      "loss": 0.0002,
      "step": 3480
    },
    {
      "epoch": 388.95522388059703,
      "grad_norm": 0.0020528146997094154,
      "learning_rate": 1.9065301724057297e-05,
      "loss": 0.0001,
      "step": 3500
    },
    {
      "epoch": 391.1194029850746,
      "grad_norm": 0.0014340868219733238,
      "learning_rate": 1.9003307124526177e-05,
      "loss": 0.0001,
      "step": 3520
    },
    {
      "epoch": 393.35820895522386,
      "grad_norm": 0.0017877502832561731,
      "learning_rate": 1.8941092412211852e-05,
      "loss": 0.0001,
      "step": 3540
    },
    {
      "epoch": 395.5970149253731,
      "grad_norm": 0.0020104413852095604,
      "learning_rate": 1.887865969285118e-05,
      "loss": 0.0001,
      "step": 3560
    },
    {
      "epoch": 397.8358208955224,
      "grad_norm": 0.0014185986947268248,
      "learning_rate": 1.881601107955974e-05,
      "loss": 0.0001,
      "step": 3580
    },
    {
      "epoch": 400.0,
      "grad_norm": 0.008745168335735798,
      "learning_rate": 1.8753148692760326e-05,
      "loss": 0.0001,
      "step": 3600
    },
    {
      "epoch": 402.23880597014926,
      "grad_norm": 0.003959805238991976,
      "learning_rate": 1.8690074660111158e-05,
      "loss": 0.0001,
      "step": 3620
    },
    {
      "epoch": 404.4776119402985,
      "grad_norm": 0.003372961189597845,
      "learning_rate": 1.86267911164339e-05,
      "loss": 0.0001,
      "step": 3640
    },
    {
      "epoch": 406.7164179104478,
      "grad_norm": 0.00456079700961709,
      "learning_rate": 1.856330020364137e-05,
      "loss": 0.0001,
      "step": 3660
    },
    {
      "epoch": 408.95522388059703,
      "grad_norm": 0.0028871018439531326,
      "learning_rate": 1.8499604070665068e-05,
      "loss": 0.0001,
      "step": 3680
    },
    {
      "epoch": 411.1194029850746,
      "grad_norm": 0.0022451337426900864,
      "learning_rate": 1.8435704873382433e-05,
      "loss": 0.0001,
      "step": 3700
    },
    {
      "epoch": 413.35820895522386,
      "grad_norm": 0.004020632244646549,
      "learning_rate": 1.8371604774543877e-05,
      "loss": 0.0001,
      "step": 3720
    },
    {
      "epoch": 415.5970149253731,
      "grad_norm": 0.0023316554725170135,
      "learning_rate": 1.8307305943699583e-05,
      "loss": 0.0001,
      "step": 3740
    },
    {
      "epoch": 417.8358208955224,
      "grad_norm": 0.0024893051013350487,
      "learning_rate": 1.8242810557126073e-05,
      "loss": 0.0001,
      "step": 3760
    },
    {
      "epoch": 420.0,
      "grad_norm": 0.00569692999124527,
      "learning_rate": 1.817812079775255e-05,
      "loss": 0.0001,
      "step": 3780
    },
    {
      "epoch": 422.23880597014926,
      "grad_norm": 0.0020333954598754644,
      "learning_rate": 1.8113238855087013e-05,
      "loss": 0.0001,
      "step": 3800
    },
    {
      "epoch": 424.4776119402985,
      "grad_norm": 0.0021604259964078665,
      "learning_rate": 1.8048166925142153e-05,
      "loss": 0.0001,
      "step": 3820
    },
    {
      "epoch": 426.7164179104478,
      "grad_norm": 0.0014851524028927088,
      "learning_rate": 1.7982907210361028e-05,
      "loss": 0.0001,
      "step": 3840
    },
    {
      "epoch": 428.95522388059703,
      "grad_norm": 0.001454701297916472,
      "learning_rate": 1.7917461919542514e-05,
      "loss": 0.0001,
      "step": 3860
    },
    {
      "epoch": 431.1194029850746,
      "grad_norm": 0.0021342297550290823,
      "learning_rate": 1.7851833267766536e-05,
      "loss": 0.0001,
      "step": 3880
    },
    {
      "epoch": 433.35820895522386,
      "grad_norm": 0.0012878149282187223,
      "learning_rate": 1.7786023476319124e-05,
      "loss": 0.0001,
      "step": 3900
    },
    {
      "epoch": 435.5970149253731,
      "grad_norm": 0.0020811050198972225,
      "learning_rate": 1.7720034772617196e-05,
      "loss": 0.0001,
      "step": 3920
    },
    {
      "epoch": 437.8358208955224,
      "grad_norm": 0.0032909638248384,
      "learning_rate": 1.7653869390133186e-05,
      "loss": 0.0001,
      "step": 3940
    },
    {
      "epoch": 440.0,
      "grad_norm": 0.001900470000691712,
      "learning_rate": 1.758752956831947e-05,
      "loss": 0.0001,
      "step": 3960
    },
    {
      "epoch": 442.23880597014926,
      "grad_norm": 0.002274793107062578,
      "learning_rate": 1.7521017552532518e-05,
      "loss": 0.0001,
      "step": 3980
    },
    {
      "epoch": 444.4776119402985,
      "grad_norm": 0.002871267031878233,
      "learning_rate": 1.7454335593956947e-05,
      "loss": 0.0001,
      "step": 4000
    },
    {
      "epoch": 446.7164179104478,
      "grad_norm": 0.001201353850774467,
      "learning_rate": 1.73874859495293e-05,
      "loss": 0.0001,
      "step": 4020
    },
    {
      "epoch": 448.95522388059703,
      "grad_norm": 0.001985352486371994,
      "learning_rate": 1.7320470881861657e-05,
      "loss": 0.0001,
      "step": 4040
    },
    {
      "epoch": 451.1194029850746,
      "grad_norm": 0.0032499961089342833,
      "learning_rate": 1.7253292659165062e-05,
      "loss": 0.0001,
      "step": 4060
    },
    {
      "epoch": 453.35820895522386,
      "grad_norm": 0.0017004001419991255,
      "learning_rate": 1.7185953555172762e-05,
      "loss": 0.0001,
      "step": 4080
    },
    {
      "epoch": 455.5970149253731,
      "grad_norm": 0.0016323637682944536,
      "learning_rate": 1.7118455849063227e-05,
      "loss": 0.0001,
      "step": 4100
    },
    {
      "epoch": 457.8358208955224,
      "grad_norm": 0.001924198237247765,
      "learning_rate": 1.7050801825383018e-05,
      "loss": 0.0001,
      "step": 4120
    },
    {
      "epoch": 460.0,
      "grad_norm": 0.005083196796476841,
      "learning_rate": 1.6982993773969468e-05,
      "loss": 0.0001,
      "step": 4140
    },
    {
      "epoch": 462.23880597014926,
      "grad_norm": 0.0019517546752467752,
      "learning_rate": 1.6915033989873185e-05,
      "loss": 0.0001,
      "step": 4160
    },
    {
      "epoch": 464.4776119402985,
      "grad_norm": 0.0024330606684088707,
      "learning_rate": 1.6846924773280354e-05,
      "loss": 0.0001,
      "step": 4180
    },
    {
      "epoch": 466.7164179104478,
      "grad_norm": 0.0013925837120041251,
      "learning_rate": 1.677866842943489e-05,
      "loss": 0.0001,
      "step": 4200
    },
    {
      "epoch": 468.95522388059703,
      "grad_norm": 0.0018979287706315517,
      "learning_rate": 1.6710267268560437e-05,
      "loss": 0.0001,
      "step": 4220
    },
    {
      "epoch": 471.1194029850746,
      "grad_norm": 0.0012375926598906517,
      "learning_rate": 1.6641723605782138e-05,
      "loss": 0.0001,
      "step": 4240
    },
    {
      "epoch": 473.35820895522386,
      "grad_norm": 0.00215753260999918,
      "learning_rate": 1.657303976104831e-05,
      "loss": 0.0001,
      "step": 4260
    },
    {
      "epoch": 475.5970149253731,
      "grad_norm": 0.0019986603874713182,
      "learning_rate": 1.6504218059051908e-05,
      "loss": 0.0001,
      "step": 4280
    },
    {
      "epoch": 477.8358208955224,
      "grad_norm": 0.0013567728456109762,
      "learning_rate": 1.6435260829151827e-05,
      "loss": 0.0001,
      "step": 4300
    },
    {
      "epoch": 480.0,
      "grad_norm": 0.003357323119416833,
      "learning_rate": 1.6366170405294095e-05,
      "loss": 0.0001,
      "step": 4320
    },
    {
      "epoch": 482.23880597014926,
      "grad_norm": 0.001501187332905829,
      "learning_rate": 1.6296949125932858e-05,
      "loss": 0.0001,
      "step": 4340
    },
    {
      "epoch": 484.4776119402985,
      "grad_norm": 0.00195763329975307,
      "learning_rate": 1.622759933395123e-05,
      "loss": 0.0001,
      "step": 4360
    },
    {
      "epoch": 486.7164179104478,
      "grad_norm": 0.0009872035589069128,
      "learning_rate": 1.6158123376581995e-05,
      "loss": 0.0001,
      "step": 4380
    },
    {
      "epoch": 488.95522388059703,
      "grad_norm": 0.002332612406462431,
      "learning_rate": 1.6088523605328182e-05,
      "loss": 0.0001,
      "step": 4400
    },
    {
      "epoch": 491.1194029850746,
      "grad_norm": 0.0006971654947847128,
      "learning_rate": 1.6018802375883442e-05,
      "loss": 0.0001,
      "step": 4420
    },
    {
      "epoch": 493.35820895522386,
      "grad_norm": 0.0017788114491850138,
      "learning_rate": 1.594896204805235e-05,
      "loss": 0.0001,
      "step": 4440
    },
    {
      "epoch": 495.5970149253731,
      "grad_norm": 0.0014445038978010416,
      "learning_rate": 1.587900498567051e-05,
      "loss": 0.0001,
      "step": 4460
    },
    {
      "epoch": 497.8358208955224,
      "grad_norm": 0.0014976944075897336,
      "learning_rate": 1.580893355652456e-05,
      "loss": 0.0001,
      "step": 4480
    },
    {
      "epoch": 500.0,
      "grad_norm": 0.0050397831946611404,
      "learning_rate": 1.5738750132272024e-05,
      "loss": 0.0001,
      "step": 4500
    },
    {
      "epoch": 502.23880597014926,
      "grad_norm": 0.0020078234374523163,
      "learning_rate": 1.566845708836105e-05,
      "loss": 0.0001,
      "step": 4520
    },
    {
      "epoch": 504.4776119402985,
      "grad_norm": 0.0012000743299722672,
      "learning_rate": 1.559805680395e-05,
      "loss": 0.0001,
      "step": 4540
    },
    {
      "epoch": 506.7164179104478,
      "grad_norm": 0.0013787037460133433,
      "learning_rate": 1.552755166182693e-05,
      "loss": 0.0001,
      "step": 4560
    },
    {
      "epoch": 508.95522388059703,
      "grad_norm": 0.0009792454075068235,
      "learning_rate": 1.5456944048328943e-05,
      "loss": 0.0001,
      "step": 4580
    },
    {
      "epoch": 511.1194029850746,
      "grad_norm": 0.0013323045568540692,
      "learning_rate": 1.5386236353261403e-05,
      "loss": 0.0001,
      "step": 4600
    },
    {
      "epoch": 513.3582089552239,
      "grad_norm": 0.0016361515736207366,
      "learning_rate": 1.531543096981709e-05,
      "loss": 0.0001,
      "step": 4620
    },
    {
      "epoch": 515.5970149253732,
      "grad_norm": 0.0014848212013021111,
      "learning_rate": 1.524453029449515e-05,
      "loss": 0.0001,
      "step": 4640
    },
    {
      "epoch": 517.8358208955224,
      "grad_norm": 0.0016375686973333359,
      "learning_rate": 1.517353672702001e-05,
      "loss": 0.0001,
      "step": 4660
    },
    {
      "epoch": 520.0,
      "grad_norm": 0.0012116986326873302,
      "learning_rate": 1.5102452670260153e-05,
      "loss": 0.0001,
      "step": 4680
    },
    {
      "epoch": 522.2388059701492,
      "grad_norm": 0.0012591533595696092,
      "learning_rate": 1.5031280530146793e-05,
      "loss": 0.0001,
      "step": 4700
    },
    {
      "epoch": 524.4776119402985,
      "grad_norm": 0.0012761524412781,
      "learning_rate": 1.496002271559243e-05,
      "loss": 0.0001,
      "step": 4720
    },
    {
      "epoch": 526.7164179104477,
      "grad_norm": 0.001249807421118021,
      "learning_rate": 1.488868163840933e-05,
      "loss": 0.0001,
      "step": 4740
    },
    {
      "epoch": 528.955223880597,
      "grad_norm": 0.0010314078535884619,
      "learning_rate": 1.481725971322789e-05,
      "loss": 0.0001,
      "step": 4760
    },
    {
      "epoch": 531.1194029850747,
      "grad_norm": 0.0010292751248925924,
      "learning_rate": 1.474575935741491e-05,
      "loss": 0.0001,
      "step": 4780
    },
    {
      "epoch": 533.3582089552239,
      "grad_norm": 0.0012603721115738153,
      "learning_rate": 1.4674182990991772e-05,
      "loss": 0.0001,
      "step": 4800
    },
    {
      "epoch": 535.5970149253732,
      "grad_norm": 0.0018089601071551442,
      "learning_rate": 1.4602533036552541e-05,
      "loss": 0.0001,
      "step": 4820
    },
    {
      "epoch": 537.8358208955224,
      "grad_norm": 0.001184234512038529,
      "learning_rate": 1.4530811919181958e-05,
      "loss": 0.0001,
      "step": 4840
    },
    {
      "epoch": 540.0,
      "grad_norm": 0.0029738908633589745,
      "learning_rate": 1.4459022066373368e-05,
      "loss": 0.0001,
      "step": 4860
    },
    {
      "epoch": 542.2388059701492,
      "grad_norm": 0.001774693955667317,
      "learning_rate": 1.4387165907946559e-05,
      "loss": 0.0001,
      "step": 4880
    },
    {
      "epoch": 544.4776119402985,
      "grad_norm": 0.002314629266038537,
      "learning_rate": 1.4315245875965509e-05,
      "loss": 0.0001,
      "step": 4900
    },
    {
      "epoch": 546.7164179104477,
      "grad_norm": 0.001110636629164219,
      "learning_rate": 1.4243264404656078e-05,
      "loss": 0.0001,
      "step": 4920
    },
    {
      "epoch": 548.955223880597,
      "grad_norm": 0.0016800904413685203,
      "learning_rate": 1.4171223930323629e-05,
      "loss": 0.0001,
      "step": 4940
    },
    {
      "epoch": 551.1194029850747,
      "grad_norm": 0.001010113162919879,
      "learning_rate": 1.4099126891270556e-05,
      "loss": 0.0001,
      "step": 4960
    },
    {
      "epoch": 553.3582089552239,
      "grad_norm": 0.0009277783101424575,
      "learning_rate": 1.4026975727713748e-05,
      "loss": 0.0001,
      "step": 4980
    },
    {
      "epoch": 555.5970149253732,
      "grad_norm": 0.0019119143253192306,
      "learning_rate": 1.3954772881702017e-05,
      "loss": 0.0001,
      "step": 5000
    },
    {
      "epoch": 557.8358208955224,
      "grad_norm": 0.0009539810125716031,
      "learning_rate": 1.3882520797033432e-05,
      "loss": 0.0001,
      "step": 5020
    },
    {
      "epoch": 560.0,
      "grad_norm": 0.0020731536205857992,
      "learning_rate": 1.3810221919172608e-05,
      "loss": 0.0001,
      "step": 5040
    },
    {
      "epoch": 562.2388059701492,
      "grad_norm": 0.0014182530576363206,
      "learning_rate": 1.3737878695167935e-05,
      "loss": 0.0001,
      "step": 5060
    },
    {
      "epoch": 564.4776119402985,
      "grad_norm": 0.001460499013774097,
      "learning_rate": 1.3665493573568756e-05,
      "loss": 0.0,
      "step": 5080
    },
    {
      "epoch": 566.7164179104477,
      "grad_norm": 0.0008267884259112179,
      "learning_rate": 1.3593069004342484e-05,
      "loss": 0.0001,
      "step": 5100
    },
    {
      "epoch": 568.955223880597,
      "grad_norm": 0.0009405585005879402,
      "learning_rate": 1.3520607438791705e-05,
      "loss": 0.0001,
      "step": 5120
    },
    {
      "epoch": 571.1194029850747,
      "grad_norm": 0.0019862239714711905,
      "learning_rate": 1.3448111329471174e-05,
      "loss": 0.0001,
      "step": 5140
    },
    {
      "epoch": 573.3582089552239,
      "grad_norm": 0.001068589510396123,
      "learning_rate": 1.3375583130104843e-05,
      "loss": 0.0,
      "step": 5160
    },
    {
      "epoch": 575.5970149253732,
      "grad_norm": 0.0007239418919198215,
      "learning_rate": 1.3303025295502775e-05,
      "loss": 0.0,
      "step": 5180
    },
    {
      "epoch": 577.8358208955224,
      "grad_norm": 0.0009932474931702018,
      "learning_rate": 1.3230440281478085e-05,
      "loss": 0.0001,
      "step": 5200
    },
    {
      "epoch": 580.0,
      "grad_norm": 0.0010877378517761827,
      "learning_rate": 1.3157830544763805e-05,
      "loss": 0.0,
      "step": 5220
    },
    {
      "epoch": 582.2388059701492,
      "grad_norm": 0.0005925751756876707,
      "learning_rate": 1.308519854292975e-05,
      "loss": 0.0001,
      "step": 5240
    },
    {
      "epoch": 584.4776119402985,
      "grad_norm": 0.0012744300765916705,
      "learning_rate": 1.3012546734299313e-05,
      "loss": 0.0001,
      "step": 5260
    },
    {
      "epoch": 586.7164179104477,
      "grad_norm": 0.0010712166549637914,
      "learning_rate": 1.2939877577866285e-05,
      "loss": 0.0,
      "step": 5280
    },
    {
      "epoch": 588.955223880597,
      "grad_norm": 0.0018705272814258933,
      "learning_rate": 1.2867193533211604e-05,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 591.1194029850747,
      "grad_norm": 0.0011482429690659046,
      "learning_rate": 1.279449706042013e-05,
      "loss": 0.0,
      "step": 5320
    },
    {
      "epoch": 593.3582089552239,
      "grad_norm": 0.0011647655628621578,
      "learning_rate": 1.2721790619997357e-05,
      "loss": 0.0001,
      "step": 5340
    },
    {
      "epoch": 595.5970149253732,
      "grad_norm": 0.0009191228309646249,
      "learning_rate": 1.2649076672786159e-05,
      "loss": 0.0,
      "step": 5360
    },
    {
      "epoch": 597.8358208955224,
      "grad_norm": 0.001077004591934383,
      "learning_rate": 1.2576357679883483e-05,
      "loss": 0.0,
      "step": 5380
    },
    {
      "epoch": 600.0,
      "grad_norm": 0.0020363451912999153,
      "learning_rate": 1.2503636102557042e-05,
      "loss": 0.0001,
      "step": 5400
    },
    {
      "epoch": 602.2388059701492,
      "grad_norm": 0.0011188364587724209,
      "learning_rate": 1.2430914402162046e-05,
      "loss": 0.0,
      "step": 5420
    },
    {
      "epoch": 604.4776119402985,
      "grad_norm": 0.0007667497266083956,
      "learning_rate": 1.2358195040057848e-05,
      "loss": 0.0,
      "step": 5440
    },
    {
      "epoch": 606.7164179104477,
      "grad_norm": 0.0010886101517826319,
      "learning_rate": 1.2285480477524668e-05,
      "loss": 0.0,
      "step": 5460
    },
    {
      "epoch": 608.955223880597,
      "grad_norm": 0.001832050271332264,
      "learning_rate": 1.2212773175680282e-05,
      "loss": 0.0,
      "step": 5480
    },
    {
      "epoch": 611.1194029850747,
      "grad_norm": 0.0006505479686893523,
      "learning_rate": 1.2140075595396708e-05,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 613.3582089552239,
      "grad_norm": 0.0013160720700398088,
      "learning_rate": 1.2067390197216936e-05,
      "loss": 0.0,
      "step": 5520
    },
    {
      "epoch": 615.5970149253732,
      "grad_norm": 0.0009404080919921398,
      "learning_rate": 1.199471944127163e-05,
      "loss": 0.0,
      "step": 5540
    },
    {
      "epoch": 617.8358208955224,
      "grad_norm": 0.0006422387668862939,
      "learning_rate": 1.1922065787195877e-05,
      "loss": 0.0,
      "step": 5560
    },
    {
      "epoch": 620.0,
      "grad_norm": 0.002639280864968896,
      "learning_rate": 1.1849431694045917e-05,
      "loss": 0.0,
      "step": 5580
    },
    {
      "epoch": 622.2388059701492,
      "grad_norm": 0.0011021033860743046,
      "learning_rate": 1.1776819620215932e-05,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 624.4776119402985,
      "grad_norm": 0.000831076642498374,
      "learning_rate": 1.1704232023354843e-05,
      "loss": 0.0,
      "step": 5620
    },
    {
      "epoch": 626.7164179104477,
      "grad_norm": 0.0010052151046693325,
      "learning_rate": 1.1631671360283089e-05,
      "loss": 0.0,
      "step": 5640
    },
    {
      "epoch": 628.955223880597,
      "grad_norm": 0.0008363358792848885,
      "learning_rate": 1.1559140086909524e-05,
      "loss": 0.0,
      "step": 5660
    },
    {
      "epoch": 631.1194029850747,
      "grad_norm": 0.000636950833722949,
      "learning_rate": 1.1486640658148267e-05,
      "loss": 0.0,
      "step": 5680
    },
    {
      "epoch": 633.3582089552239,
      "grad_norm": 0.0010654283687472343,
      "learning_rate": 1.1414175527835608e-05,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 635.5970149253732,
      "grad_norm": 0.0010423074709251523,
      "learning_rate": 1.134174714864696e-05,
      "loss": 0.0,
      "step": 5720
    },
    {
      "epoch": 637.8358208955224,
      "grad_norm": 0.0009701114613562822,
      "learning_rate": 1.1269357972013853e-05,
      "loss": 0.0,
      "step": 5740
    },
    {
      "epoch": 640.0,
      "grad_norm": 0.0008817517082206905,
      "learning_rate": 1.1197010448040958e-05,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 642.2388059701492,
      "grad_norm": 0.0012460853904485703,
      "learning_rate": 1.112470702542316e-05,
      "loss": 0.0,
      "step": 5780
    },
    {
      "epoch": 644.4776119402985,
      "grad_norm": 0.0005273736896924675,
      "learning_rate": 1.1052450151362661e-05,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 646.7164179104477,
      "grad_norm": 0.0007604333222843707,
      "learning_rate": 1.0980242271486186e-05,
      "loss": 0.0,
      "step": 5820
    },
    {
      "epoch": 648.955223880597,
      "grad_norm": 0.0007352626998908818,
      "learning_rate": 1.0908085829762183e-05,
      "loss": 0.0,
      "step": 5840
    },
    {
      "epoch": 651.1194029850747,
      "grad_norm": 0.0016441736370325089,
      "learning_rate": 1.0835983268418098e-05,
      "loss": 0.0,
      "step": 5860
    },
    {
      "epoch": 653.3582089552239,
      "grad_norm": 0.0007098026690073311,
      "learning_rate": 1.0763937027857741e-05,
      "loss": 0.0,
      "step": 5880
    },
    {
      "epoch": 655.5970149253732,
      "grad_norm": 0.0007704893359914422,
      "learning_rate": 1.0691949546578671e-05,
      "loss": 0.0,
      "step": 5900
    },
    {
      "epoch": 657.8358208955224,
      "grad_norm": 0.001369311474263668,
      "learning_rate": 1.0620023261089664e-05,
      "loss": 0.0,
      "step": 5920
    },
    {
      "epoch": 660.0,
      "grad_norm": 0.0026304135099053383,
      "learning_rate": 1.0548160605828234e-05,
      "loss": 0.0,
      "step": 5940
    },
    {
      "epoch": 662.2388059701492,
      "grad_norm": 0.0008059109677560627,
      "learning_rate": 1.0476364013078258e-05,
      "loss": 0.0,
      "step": 5960
    },
    {
      "epoch": 664.4776119402985,
      "grad_norm": 0.002615858567878604,
      "learning_rate": 1.0404635912887642e-05,
      "loss": 0.0,
      "step": 5980
    },
    {
      "epoch": 666.7164179104477,
      "grad_norm": 0.0009784355061128736,
      "learning_rate": 1.033297873298608e-05,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 668.955223880597,
      "grad_norm": 0.0010149333393201232,
      "learning_rate": 1.0261394898702858e-05,
      "loss": 0.0,
      "step": 6020
    },
    {
      "epoch": 671.1194029850747,
      "grad_norm": 0.002778242342174053,
      "learning_rate": 1.0189886832884806e-05,
      "loss": 0.0,
      "step": 6040
    },
    {
      "epoch": 673.3582089552239,
      "grad_norm": 0.0009190621203742921,
      "learning_rate": 1.0118456955814264e-05,
      "loss": 0.0,
      "step": 6060
    },
    {
      "epoch": 675.5970149253732,
      "grad_norm": 0.0009869952918961644,
      "learning_rate": 1.0047107685127173e-05,
      "loss": 0.0,
      "step": 6080
    },
    {
      "epoch": 677.8358208955224,
      "grad_norm": 0.0005981990834698081,
      "learning_rate": 9.975841435731243e-06,
      "loss": 0.0,
      "step": 6100
    },
    {
      "epoch": 680.0,
      "grad_norm": 0.0006419108249247074,
      "learning_rate": 9.904660619724233e-06,
      "loss": 0.0,
      "step": 6120
    },
    {
      "epoch": 682.2388059701492,
      "grad_norm": 0.0013811043463647366,
      "learning_rate": 9.833567646312297e-06,
      "loss": 0.0,
      "step": 6140
    },
    {
      "epoch": 684.4776119402985,
      "grad_norm": 0.0007540204678662121,
      "learning_rate": 9.76256492172843e-06,
      "loss": 0.0,
      "step": 6160
    },
    {
      "epoch": 686.7164179104477,
      "grad_norm": 0.0004271567740943283,
      "learning_rate": 9.691654849151055e-06,
      "loss": 0.0,
      "step": 6180
    },
    {
      "epoch": 688.955223880597,
      "grad_norm": 0.0009330298635177314,
      "learning_rate": 9.62083982862266e-06,
      "loss": 0.0,
      "step": 6200
    },
    {
      "epoch": 691.1194029850747,
      "grad_norm": 0.0011577745899558067,
      "learning_rate": 9.550122256968587e-06,
      "loss": 0.0,
      "step": 6220
    },
    {
      "epoch": 693.3582089552239,
      "grad_norm": 0.0008310994016937912,
      "learning_rate": 9.479504527715872e-06,
      "loss": 0.0,
      "step": 6240
    },
    {
      "epoch": 695.5970149253732,
      "grad_norm": 0.0008909520111046731,
      "learning_rate": 9.408989031012281e-06,
      "loss": 0.0,
      "step": 6260
    },
    {
      "epoch": 697.8358208955224,
      "grad_norm": 0.0007476545870304108,
      "learning_rate": 9.338578153545376e-06,
      "loss": 0.0,
      "step": 6280
    },
    {
      "epoch": 700.0,
      "grad_norm": 0.0017838868079707026,
      "learning_rate": 9.268274278461744e-06,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 702.2388059701492,
      "grad_norm": 0.0004874761216342449,
      "learning_rate": 9.198079785286351e-06,
      "loss": 0.0,
      "step": 6320
    },
    {
      "epoch": 704.4776119402985,
      "grad_norm": 0.0004659541882574558,
      "learning_rate": 9.127997049841976e-06,
      "loss": 0.0,
      "step": 6340
    },
    {
      "epoch": 706.7164179104477,
      "grad_norm": 0.00046509868116118014,
      "learning_rate": 9.058028444168831e-06,
      "loss": 0.0,
      "step": 6360
    },
    {
      "epoch": 708.955223880597,
      "grad_norm": 0.0014172284863889217,
      "learning_rate": 8.98817633644424e-06,
      "loss": 0.0,
      "step": 6380
    },
    {
      "epoch": 711.1194029850747,
      "grad_norm": 0.0007742952439002693,
      "learning_rate": 8.91844309090252e-06,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 713.3582089552239,
      "grad_norm": 0.0005964635056443512,
      "learning_rate": 8.848831067754947e-06,
      "loss": 0.0,
      "step": 6420
    },
    {
      "epoch": 715.5970149253732,
      "grad_norm": 0.0006032889359630644,
      "learning_rate": 8.77934262310985e-06,
      "loss": 0.0,
      "step": 6440
    },
    {
      "epoch": 717.8358208955224,
      "grad_norm": 0.0005989334895275533,
      "learning_rate": 8.7099801088929e-06,
      "loss": 0.0,
      "step": 6460
    },
    {
      "epoch": 720.0,
      "grad_norm": 0.0007943432428874075,
      "learning_rate": 8.64074587276749e-06,
      "loss": 0.0,
      "step": 6480
    },
    {
      "epoch": 722.2388059701492,
      "grad_norm": 0.0005796041223220527,
      "learning_rate": 8.571642258055278e-06,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 724.4776119402985,
      "grad_norm": 0.0007586771389469504,
      "learning_rate": 8.502671603656856e-06,
      "loss": 0.0,
      "step": 6520
    },
    {
      "epoch": 726.7164179104477,
      "grad_norm": 0.0005014849593862891,
      "learning_rate": 8.433836243972627e-06,
      "loss": 0.0,
      "step": 6540
    },
    {
      "epoch": 728.955223880597,
      "grad_norm": 0.0011192781385034323,
      "learning_rate": 8.365138508823753e-06,
      "loss": 0.0,
      "step": 6560
    },
    {
      "epoch": 731.1194029850747,
      "grad_norm": 0.0010202362900599837,
      "learning_rate": 8.29658072337333e-06,
      "loss": 0.0,
      "step": 6580
    },
    {
      "epoch": 733.3582089552239,
      "grad_norm": 0.0005062835989519954,
      "learning_rate": 8.228165208047661e-06,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 735.5970149253732,
      "grad_norm": 0.0008783891680650413,
      "learning_rate": 8.159894278457748e-06,
      "loss": 0.0,
      "step": 6620
    },
    {
      "epoch": 737.8358208955224,
      "grad_norm": 0.0008603172609582543,
      "learning_rate": 8.0917702453209e-06,
      "loss": 0.0,
      "step": 6640
    },
    {
      "epoch": 740.0,
      "grad_norm": 0.002511903177946806,
      "learning_rate": 8.023795414382517e-06,
      "loss": 0.0,
      "step": 6660
    },
    {
      "epoch": 742.2388059701492,
      "grad_norm": 0.0009021435980685055,
      "learning_rate": 7.95597208633807e-06,
      "loss": 0.0,
      "step": 6680
    },
    {
      "epoch": 744.4776119402985,
      "grad_norm": 0.0005135972751304507,
      "learning_rate": 7.888302556755223e-06,
      "loss": 0.0,
      "step": 6700
    },
    {
      "epoch": 746.7164179104477,
      "grad_norm": 0.00048469152534380555,
      "learning_rate": 7.820789115996119e-06,
      "loss": 0.0,
      "step": 6720
    },
    {
      "epoch": 748.955223880597,
      "grad_norm": 0.0005160547443665564,
      "learning_rate": 7.753434049139885e-06,
      "loss": 0.0,
      "step": 6740
    },
    {
      "epoch": 751.1194029850747,
      "grad_norm": 0.0007457815227098763,
      "learning_rate": 7.686239635905275e-06,
      "loss": 0.0,
      "step": 6760
    },
    {
      "epoch": 753.3582089552239,
      "grad_norm": 0.0007279484416358173,
      "learning_rate": 7.619208150573519e-06,
      "loss": 0.0,
      "step": 6780
    },
    {
      "epoch": 755.5970149253732,
      "grad_norm": 0.000781217881012708,
      "learning_rate": 7.552341861911347e-06,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 757.8358208955224,
      "grad_norm": 0.0005768047412857413,
      "learning_rate": 7.485643033094175e-06,
      "loss": 0.0,
      "step": 6820
    },
    {
      "epoch": 760.0,
      "grad_norm": 0.0007165861316025257,
      "learning_rate": 7.419113921629553e-06,
      "loss": 0.0,
      "step": 6840
    },
    {
      "epoch": 762.2388059701492,
      "grad_norm": 0.0009193776058964431,
      "learning_rate": 7.352756779280712e-06,
      "loss": 0.0,
      "step": 6860
    },
    {
      "epoch": 764.4776119402985,
      "grad_norm": 0.0009236810728907585,
      "learning_rate": 7.2865738519903636e-06,
      "loss": 0.0,
      "step": 6880
    },
    {
      "epoch": 766.7164179104477,
      "grad_norm": 0.000512905593495816,
      "learning_rate": 7.220567379804706e-06,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 768.955223880597,
      "grad_norm": 0.0009927477221935987,
      "learning_rate": 7.154739596797566e-06,
      "loss": 0.0,
      "step": 6920
    },
    {
      "epoch": 771.1194029850747,
      "grad_norm": 0.0007601341931149364,
      "learning_rate": 7.089092730994831e-06,
      "loss": 0.0,
      "step": 6940
    },
    {
      "epoch": 773.3582089552239,
      "grad_norm": 0.0008636896382085979,
      "learning_rate": 7.023629004298979e-06,
      "loss": 0.0,
      "step": 6960
    },
    {
      "epoch": 775.5970149253732,
      "grad_norm": 0.000930666399654001,
      "learning_rate": 6.958350632413943e-06,
      "loss": 0.0,
      "step": 6980
    },
    {
      "epoch": 777.8358208955224,
      "grad_norm": 0.0006308565498329699,
      "learning_rate": 6.893259824770061e-06,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 780.0,
      "grad_norm": 0.0009820308769121766,
      "learning_rate": 6.828358784449343e-06,
      "loss": 0.0,
      "step": 7020
    },
    {
      "epoch": 782.2388059701492,
      "grad_norm": 0.0012574299471452832,
      "learning_rate": 6.763649708110851e-06,
      "loss": 0.0,
      "step": 7040
    },
    {
      "epoch": 784.4776119402985,
      "grad_norm": 0.00043479446321725845,
      "learning_rate": 6.699134785916389e-06,
      "loss": 0.0,
      "step": 7060
    },
    {
      "epoch": 786.7164179104477,
      "grad_norm": 0.0006751678301952779,
      "learning_rate": 6.634816201456387e-06,
      "loss": 0.0,
      "step": 7080
    },
    {
      "epoch": 788.955223880597,
      "grad_norm": 0.0006632304284721613,
      "learning_rate": 6.570696131675934e-06,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 791.1194029850747,
      "grad_norm": 0.0005555496900342405,
      "learning_rate": 6.506776746801169e-06,
      "loss": 0.0,
      "step": 7120
    },
    {
      "epoch": 793.3582089552239,
      "grad_norm": 0.0006287310970947146,
      "learning_rate": 6.443060210265772e-06,
      "loss": 0.0,
      "step": 7140
    },
    {
      "epoch": 795.5970149253732,
      "grad_norm": 0.0008155651739798486,
      "learning_rate": 6.37954867863777e-06,
      "loss": 0.0,
      "step": 7160
    },
    {
      "epoch": 797.8358208955224,
      "grad_norm": 0.0008980203419923782,
      "learning_rate": 6.316244301546531e-06,
      "loss": 0.0,
      "step": 7180
    },
    {
      "epoch": 800.0,
      "grad_norm": 0.0014894296182319522,
      "learning_rate": 6.253149221610005e-06,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 802.2388059701492,
      "grad_norm": 0.0005998049746267498,
      "learning_rate": 6.190265574362233e-06,
      "loss": 0.0,
      "step": 7220
    },
    {
      "epoch": 804.4776119402985,
      "grad_norm": 0.000736903864890337,
      "learning_rate": 6.127595488181023e-06,
      "loss": 0.0,
      "step": 7240
    },
    {
      "epoch": 806.7164179104477,
      "grad_norm": 0.0007470638956874609,
      "learning_rate": 6.065141084215943e-06,
      "loss": 0.0,
      "step": 7260
    },
    {
      "epoch": 808.955223880597,
      "grad_norm": 0.0011020019883289933,
      "learning_rate": 6.002904476316519e-06,
      "loss": 0.0,
      "step": 7280
    },
    {
      "epoch": 811.1194029850747,
      "grad_norm": 0.000863239576574415,
      "learning_rate": 5.940887770960689e-06,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 813.3582089552239,
      "grad_norm": 0.0007632841588929296,
      "learning_rate": 5.879093067183507e-06,
      "loss": 0.0,
      "step": 7320
    },
    {
      "epoch": 815.5970149253732,
      "grad_norm": 0.0007071425789035857,
      "learning_rate": 5.817522456506093e-06,
      "loss": 0.0,
      "step": 7340
    },
    {
      "epoch": 817.8358208955224,
      "grad_norm": 0.0003815031086560339,
      "learning_rate": 5.756178022864862e-06,
      "loss": 0.0,
      "step": 7360
    },
    {
      "epoch": 820.0,
      "grad_norm": 0.0015674370806664228,
      "learning_rate": 5.695061842540966e-06,
      "loss": 0.0,
      "step": 7380
    },
    {
      "epoch": 822.2388059701492,
      "grad_norm": 0.0004593594931066036,
      "learning_rate": 5.6341759840900315e-06,
      "loss": 0.0,
      "step": 7400
    },
    {
      "epoch": 824.4776119402985,
      "grad_norm": 0.001538860728032887,
      "learning_rate": 5.5735225082721474e-06,
      "loss": 0.0,
      "step": 7420
    },
    {
      "epoch": 826.7164179104477,
      "grad_norm": 0.0007682334398850799,
      "learning_rate": 5.513103467982105e-06,
      "loss": 0.0,
      "step": 7440
    },
    {
      "epoch": 828.955223880597,
      "grad_norm": 0.0003649089194368571,
      "learning_rate": 5.452920908179948e-06,
      "loss": 0.0,
      "step": 7460
    },
    {
      "epoch": 831.1194029850747,
      "grad_norm": 0.0009476787527091801,
      "learning_rate": 5.3929768658217e-06,
      "loss": 0.0,
      "step": 7480
    },
    {
      "epoch": 833.3582089552239,
      "grad_norm": 0.000721436575986445,
      "learning_rate": 5.333273369790487e-06,
      "loss": 0.0,
      "step": 7500
    },
    {
      "epoch": 835.5970149253732,
      "grad_norm": 0.0008718110038898885,
      "learning_rate": 5.273812440827816e-06,
      "loss": 0.0,
      "step": 7520
    },
    {
      "epoch": 837.8358208955224,
      "grad_norm": 0.0006835924577899277,
      "learning_rate": 5.214596091465209e-06,
      "loss": 0.0,
      "step": 7540
    },
    {
      "epoch": 840.0,
      "grad_norm": 0.0008002872345969081,
      "learning_rate": 5.155626325956071e-06,
      "loss": 0.0,
      "step": 7560
    },
    {
      "epoch": 842.2388059701492,
      "grad_norm": 0.00035170227056369185,
      "learning_rate": 5.09690514020786e-06,
      "loss": 0.0,
      "step": 7580
    },
    {
      "epoch": 844.4776119402985,
      "grad_norm": 0.0005337392794899642,
      "learning_rate": 5.038434521714548e-06,
      "loss": 0.0,
      "step": 7600
    },
    {
      "epoch": 846.7164179104477,
      "grad_norm": 0.0005325042293407023,
      "learning_rate": 4.98021644948931e-06,
      "loss": 0.0,
      "step": 7620
    },
    {
      "epoch": 848.955223880597,
      "grad_norm": 0.0008032500045374036,
      "learning_rate": 4.922252893997591e-06,
      "loss": 0.0,
      "step": 7640
    },
    {
      "epoch": 851.1194029850747,
      "grad_norm": 0.0006694815820083022,
      "learning_rate": 4.864545817090378e-06,
      "loss": 0.0,
      "step": 7660
    },
    {
      "epoch": 853.3582089552239,
      "grad_norm": 0.0005679755704477429,
      "learning_rate": 4.807097171937816e-06,
      "loss": 0.0,
      "step": 7680
    },
    {
      "epoch": 855.5970149253732,
      "grad_norm": 0.0005396080669015646,
      "learning_rate": 4.749908902963093e-06,
      "loss": 0.0,
      "step": 7700
    },
    {
      "epoch": 857.8358208955224,
      "grad_norm": 0.000724374724086374,
      "learning_rate": 4.692982945776628e-06,
      "loss": 0.0,
      "step": 7720
    },
    {
      "epoch": 860.0,
      "grad_norm": 0.0005467445589601994,
      "learning_rate": 4.636321227110574e-06,
      "loss": 0.0,
      "step": 7740
    },
    {
      "epoch": 862.2388059701492,
      "grad_norm": 0.0006950745591893792,
      "learning_rate": 4.579925664753568e-06,
      "loss": 0.0,
      "step": 7760
    },
    {
      "epoch": 864.4776119402985,
      "grad_norm": 0.0008149560890160501,
      "learning_rate": 4.5237981674858696e-06,
      "loss": 0.0,
      "step": 7780
    },
    {
      "epoch": 866.7164179104477,
      "grad_norm": 0.0005461900727823377,
      "learning_rate": 4.4679406350147165e-06,
      "loss": 0.0,
      "step": 7800
    },
    {
      "epoch": 868.955223880597,
      "grad_norm": 0.0007331480737775564,
      "learning_rate": 4.4123549579100466e-06,
      "loss": 0.0,
      "step": 7820
    },
    {
      "epoch": 871.1194029850747,
      "grad_norm": 0.0009225242538377643,
      "learning_rate": 4.357043017540498e-06,
      "loss": 0.0,
      "step": 7840
    },
    {
      "epoch": 873.3582089552239,
      "grad_norm": 0.000376750307623297,
      "learning_rate": 4.30200668600974e-06,
      "loss": 0.0,
      "step": 7860
    },
    {
      "epoch": 875.5970149253732,
      "grad_norm": 0.0005816803313791752,
      "learning_rate": 4.2472478260931205e-06,
      "loss": 0.0,
      "step": 7880
    },
    {
      "epoch": 877.8358208955224,
      "grad_norm": 0.0006346310256049037,
      "learning_rate": 4.1927682911745745e-06,
      "loss": 0.0,
      "step": 7900
    },
    {
      "epoch": 880.0,
      "grad_norm": 0.0004884686786681414,
      "learning_rate": 4.138569925183953e-06,
      "loss": 0.0,
      "step": 7920
    },
    {
      "epoch": 882.2388059701492,
      "grad_norm": 0.00047029065899550915,
      "learning_rate": 4.0846545625345694e-06,
      "loss": 0.0,
      "step": 7940
    },
    {
      "epoch": 884.4776119402985,
      "grad_norm": 0.0006646428373642266,
      "learning_rate": 4.031024028061124e-06,
      "loss": 0.0,
      "step": 7960
    },
    {
      "epoch": 886.7164179104477,
      "grad_norm": 0.0005417710053734481,
      "learning_rate": 3.977680136957948e-06,
      "loss": 0.0,
      "step": 7980
    },
    {
      "epoch": 888.955223880597,
      "grad_norm": 0.0007387445657514036,
      "learning_rate": 3.924624694717552e-06,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 891.1194029850747,
      "grad_norm": 0.0005939980619587004,
      "learning_rate": 3.8718594970695356e-06,
      "loss": 0.0,
      "step": 8020
    },
    {
      "epoch": 893.3582089552239,
      "grad_norm": 0.0005276276497170329,
      "learning_rate": 3.819386329919787e-06,
      "loss": 0.0,
      "step": 8040
    },
    {
      "epoch": 895.5970149253732,
      "grad_norm": 0.0006082855397835374,
      "learning_rate": 3.767206969290053e-06,
      "loss": 0.0,
      "step": 8060
    },
    {
      "epoch": 897.8358208955224,
      "grad_norm": 0.0004557708452921361,
      "learning_rate": 3.715323181257817e-06,
      "loss": 0.0,
      "step": 8080
    },
    {
      "epoch": 900.0,
      "grad_norm": 0.0012555093271657825,
      "learning_rate": 3.6637367218965296e-06,
      "loss": 0.0,
      "step": 8100
    },
    {
      "epoch": 902.2388059701492,
      "grad_norm": 0.000473268999485299,
      "learning_rate": 3.6124493372161743e-06,
      "loss": 0.0,
      "step": 8120
    },
    {
      "epoch": 904.4776119402985,
      "grad_norm": 0.0006635336903855205,
      "learning_rate": 3.5614627631041578e-06,
      "loss": 0.0,
      "step": 8140
    },
    {
      "epoch": 906.7164179104477,
      "grad_norm": 0.0006114333518780768,
      "learning_rate": 3.5107787252665834e-06,
      "loss": 0.0,
      "step": 8160
    },
    {
      "epoch": 908.955223880597,
      "grad_norm": 0.000535365310497582,
      "learning_rate": 3.4603989391698123e-06,
      "loss": 0.0,
      "step": 8180
    },
    {
      "epoch": 911.1194029850747,
      "grad_norm": 0.0005282066995278001,
      "learning_rate": 3.4103251099824165e-06,
      "loss": 0.0,
      "step": 8200
    },
    {
      "epoch": 913.3582089552239,
      "grad_norm": 0.0003346747253090143,
      "learning_rate": 3.3605589325174657e-06,
      "loss": 0.0,
      "step": 8220
    },
    {
      "epoch": 915.5970149253732,
      "grad_norm": 0.0007858421304263175,
      "learning_rate": 3.3111020911751596e-06,
      "loss": 0.0,
      "step": 8240
    },
    {
      "epoch": 917.8358208955224,
      "grad_norm": 0.0006953651318326592,
      "learning_rate": 3.261956259885832e-06,
      "loss": 0.0,
      "step": 8260
    },
    {
      "epoch": 920.0,
      "grad_norm": 0.00039785573608241975,
      "learning_rate": 3.2131231020532546e-06,
      "loss": 0.0,
      "step": 8280
    },
    {
      "epoch": 922.2388059701492,
      "grad_norm": 0.0006261630915105343,
      "learning_rate": 3.164604270498393e-06,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 924.4776119402985,
      "grad_norm": 0.0005445329006761312,
      "learning_rate": 3.1164014074034215e-06,
      "loss": 0.0,
      "step": 8320
    },
    {
      "epoch": 926.7164179104477,
      "grad_norm": 0.00031778422999195755,
      "learning_rate": 3.0685161442561576e-06,
      "loss": 0.0,
      "step": 8340
    },
    {
      "epoch": 928.955223880597,
      "grad_norm": 0.0004805069766007364,
      "learning_rate": 3.0209501017948406e-06,
      "loss": 0.0,
      "step": 8360
    },
    {
      "epoch": 931.1194029850747,
      "grad_norm": 0.00034813914680853486,
      "learning_rate": 2.973704889953277e-06,
      "loss": 0.0,
      "step": 8380
    },
    {
      "epoch": 933.3582089552239,
      "grad_norm": 0.0003735736827366054,
      "learning_rate": 2.9267821078063555e-06,
      "loss": 0.0,
      "step": 8400
    },
    {
      "epoch": 935.5970149253732,
      "grad_norm": 0.0007446667877957225,
      "learning_rate": 2.880183343515898e-06,
      "loss": 0.0,
      "step": 8420
    },
    {
      "epoch": 937.8358208955224,
      "grad_norm": 0.0006098021403886378,
      "learning_rate": 2.8339101742769492e-06,
      "loss": 0.0,
      "step": 8440
    },
    {
      "epoch": 940.0,
      "grad_norm": 0.0005630715750157833,
      "learning_rate": 2.7879641662643565e-06,
      "loss": 0.0,
      "step": 8460
    },
    {
      "epoch": 942.2388059701492,
      "grad_norm": 0.0005173490499146283,
      "learning_rate": 2.742346874579779e-06,
      "loss": 0.0,
      "step": 8480
    },
    {
      "epoch": 944.4776119402985,
      "grad_norm": 0.00033449626062065363,
      "learning_rate": 2.697059843199051e-06,
      "loss": 0.0,
      "step": 8500
    },
    {
      "epoch": 946.7164179104477,
      "grad_norm": 0.00048283228534273803,
      "learning_rate": 2.6521046049199165e-06,
      "loss": 0.0,
      "step": 8520
    },
    {
      "epoch": 948.955223880597,
      "grad_norm": 0.0007664241129532456,
      "learning_rate": 2.607482681310171e-06,
      "loss": 0.0,
      "step": 8540
    },
    {
      "epoch": 951.1194029850747,
      "grad_norm": 0.0003239467041566968,
      "learning_rate": 2.563195582656125e-06,
      "loss": 0.0,
      "step": 8560
    },
    {
      "epoch": 953.3582089552239,
      "grad_norm": 0.00046236038906499743,
      "learning_rate": 2.5192448079115264e-06,
      "loss": 0.0,
      "step": 8580
    },
    {
      "epoch": 955.5970149253732,
      "grad_norm": 0.000680002209264785,
      "learning_rate": 2.4756318446468002e-06,
      "loss": 0.0,
      "step": 8600
    },
    {
      "epoch": 957.8358208955224,
      "grad_norm": 0.0006144263315945864,
      "learning_rate": 2.432358168998711e-06,
      "loss": 0.0,
      "step": 8620
    },
    {
      "epoch": 960.0,
      "grad_norm": 0.0010523985838517547,
      "learning_rate": 2.3894252456203927e-06,
      "loss": 0.0,
      "step": 8640
    },
    {
      "epoch": 962.2388059701492,
      "grad_norm": 0.0005380686488933861,
      "learning_rate": 2.346834527631786e-06,
      "loss": 0.0,
      "step": 8660
    },
    {
      "epoch": 964.4776119402985,
      "grad_norm": 0.0006080212770029902,
      "learning_rate": 2.304587456570452e-06,
      "loss": 0.0,
      "step": 8680
    },
    {
      "epoch": 966.7164179104477,
      "grad_norm": 0.0005485573201440275,
      "learning_rate": 2.2626854623427772e-06,
      "loss": 0.0,
      "step": 8700
    },
    {
      "epoch": 968.955223880597,
      "grad_norm": 0.0018078753491863608,
      "learning_rate": 2.221129963175579e-06,
      "loss": 0.0,
      "step": 8720
    },
    {
      "epoch": 971.1194029850747,
      "grad_norm": 0.0005411196034401655,
      "learning_rate": 2.1799223655681044e-06,
      "loss": 0.0,
      "step": 8740
    },
    {
      "epoch": 973.3582089552239,
      "grad_norm": 0.0004979041405022144,
      "learning_rate": 2.1390640642444284e-06,
      "loss": 0.0,
      "step": 8760
    },
    {
      "epoch": 975.5970149253732,
      "grad_norm": 0.0004344309854786843,
      "learning_rate": 2.0985564421062394e-06,
      "loss": 0.0,
      "step": 8780
    },
    {
      "epoch": 977.8358208955224,
      "grad_norm": 0.0006265997071750462,
      "learning_rate": 2.058400870186039e-06,
      "loss": 0.0,
      "step": 8800
    },
    {
      "epoch": 980.0,
      "grad_norm": 0.0005783084779977798,
      "learning_rate": 2.018598707600747e-06,
      "loss": 0.0,
      "step": 8820
    },
    {
      "epoch": 982.2388059701492,
      "grad_norm": 0.0005695255822502077,
      "learning_rate": 1.9791513015056773e-06,
      "loss": 0.0,
      "step": 8840
    },
    {
      "epoch": 984.4776119402985,
      "grad_norm": 0.0004785610071849078,
      "learning_rate": 1.9400599870489603e-06,
      "loss": 0.0,
      "step": 8860
    },
    {
      "epoch": 986.7164179104477,
      "grad_norm": 0.0006177089526318014,
      "learning_rate": 1.901326087326348e-06,
      "loss": 0.0,
      "step": 8880
    },
    {
      "epoch": 988.955223880597,
      "grad_norm": 0.00044962967513129115,
      "learning_rate": 1.8629509133364268e-06,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 991.1194029850747,
      "grad_norm": 0.0006700264639221132,
      "learning_rate": 1.8249357639362627e-06,
      "loss": 0.0,
      "step": 8920
    },
    {
      "epoch": 993.3582089552239,
      "grad_norm": 0.0004574242339003831,
      "learning_rate": 1.7872819257974057e-06,
      "loss": 0.0,
      "step": 8940
    },
    {
      "epoch": 995.5970149253732,
      "grad_norm": 0.0004171405453234911,
      "learning_rate": 1.7499906733623852e-06,
      "loss": 0.0,
      "step": 8960
    },
    {
      "epoch": 997.8358208955224,
      "grad_norm": 0.000296443555271253,
      "learning_rate": 1.713063268801539e-06,
      "loss": 0.0,
      "step": 8980
    },
    {
      "epoch": 1000.0,
      "grad_norm": 0.0004567225696519017,
      "learning_rate": 1.6765009619702995e-06,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 1002.2388059701492,
      "grad_norm": 0.00036436901427805424,
      "learning_rate": 1.6403049903669157e-06,
      "loss": 0.0,
      "step": 9020
    },
    {
      "epoch": 1004.4776119402985,
      "grad_norm": 0.00055890524527058,
      "learning_rate": 1.6044765790905344e-06,
      "loss": 0.0,
      "step": 9040
    },
    {
      "epoch": 1006.7164179104477,
      "grad_norm": 0.0004374283889774233,
      "learning_rate": 1.5690169407997668e-06,
      "loss": 0.0,
      "step": 9060
    },
    {
      "epoch": 1008.955223880597,
      "grad_norm": 0.0004040939384140074,
      "learning_rate": 1.5339272756716052e-06,
      "loss": 0.0,
      "step": 9080
    },
    {
      "epoch": 1011.1194029850747,
      "grad_norm": 0.0006180020864121616,
      "learning_rate": 1.4992087713608508e-06,
      "loss": 0.0,
      "step": 9100
    },
    {
      "epoch": 1013.3582089552239,
      "grad_norm": 0.0006490048253908753,
      "learning_rate": 1.4648626029598753e-06,
      "loss": 0.0,
      "step": 9120
    },
    {
      "epoch": 1015.5970149253732,
      "grad_norm": 0.000475761917186901,
      "learning_rate": 1.4308899329588606e-06,
      "loss": 0.0,
      "step": 9140
    },
    {
      "epoch": 1017.8358208955224,
      "grad_norm": 0.0005743275978602469,
      "learning_rate": 1.3972919112064678e-06,
      "loss": 0.0,
      "step": 9160
    },
    {
      "epoch": 1020.0,
      "grad_norm": 0.0005058207898400724,
      "learning_rate": 1.364069674870895e-06,
      "loss": 0.0,
      "step": 9180
    },
    {
      "epoch": 1022.2388059701492,
      "grad_norm": 0.00047381018521264195,
      "learning_rate": 1.3312243484014137e-06,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 1024.4776119402984,
      "grad_norm": 0.0004944559186697006,
      "learning_rate": 1.29875704349028e-06,
      "loss": 0.0,
      "step": 9220
    },
    {
      "epoch": 1026.7164179104477,
      "grad_norm": 0.0006299347151070833,
      "learning_rate": 1.2666688590351333e-06,
      "loss": 0.0,
      "step": 9240
    },
    {
      "epoch": 1028.955223880597,
      "grad_norm": 0.0006949114031158388,
      "learning_rate": 1.2349608811017987e-06,
      "loss": 0.0,
      "step": 9260
    },
    {
      "epoch": 1031.1194029850747,
      "grad_norm": 0.0003812832001131028,
      "learning_rate": 1.2036341828875183e-06,
      "loss": 0.0,
      "step": 9280
    },
    {
      "epoch": 1033.358208955224,
      "grad_norm": 0.0007237119716592133,
      "learning_rate": 1.1726898246846306e-06,
      "loss": 0.0,
      "step": 9300
    },
    {
      "epoch": 1035.597014925373,
      "grad_norm": 0.0008593518286943436,
      "learning_rate": 1.1421288538446858e-06,
      "loss": 0.0,
      "step": 9320
    },
    {
      "epoch": 1037.8358208955224,
      "grad_norm": 0.0003055081469938159,
      "learning_rate": 1.1119523047430053e-06,
      "loss": 0.0,
      "step": 9340
    },
    {
      "epoch": 1040.0,
      "grad_norm": 0.001106324722059071,
      "learning_rate": 1.0821611987436475e-06,
      "loss": 0.0,
      "step": 9360
    },
    {
      "epoch": 1042.2388059701493,
      "grad_norm": 0.0005259404424577951,
      "learning_rate": 1.0527565441648623e-06,
      "loss": 0.0,
      "step": 9380
    },
    {
      "epoch": 1044.4776119402984,
      "grad_norm": 0.001041881158016622,
      "learning_rate": 1.023739336244961e-06,
      "loss": 0.0,
      "step": 9400
    },
    {
      "epoch": 1046.7164179104477,
      "grad_norm": 0.0005647270590998232,
      "learning_rate": 9.951105571086126e-07,
      "loss": 0.0,
      "step": 9420
    },
    {
      "epoch": 1048.955223880597,
      "grad_norm": 0.00030687436810694635,
      "learning_rate": 9.668711757336247e-07,
      "loss": 0.0,
      "step": 9440
    },
    {
      "epoch": 1051.1194029850747,
      "grad_norm": 0.0004456222231965512,
      "learning_rate": 9.390221479181282e-07,
      "loss": 0.0,
      "step": 9460
    },
    {
      "epoch": 1053.358208955224,
      "grad_norm": 0.0005820262595079839,
      "learning_rate": 9.115644162482492e-07,
      "loss": 0.0,
      "step": 9480
    },
    {
      "epoch": 1055.597014925373,
      "grad_norm": 0.00045780636719428003,
      "learning_rate": 8.844989100661852e-07,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 1057.8358208955224,
      "grad_norm": 0.0008594027603976429,
      "learning_rate": 8.578265454387502e-07,
      "loss": 0.0,
      "step": 9520
    },
    {
      "epoch": 1060.0,
      "grad_norm": 0.0015203960938379169,
      "learning_rate": 8.315482251263953e-07,
      "loss": 0.0,
      "step": 9540
    },
    {
      "epoch": 1062.2388059701493,
      "grad_norm": 0.00040143533260561526,
      "learning_rate": 8.056648385526222e-07,
      "loss": 0.0,
      "step": 9560
    },
    {
      "epoch": 1064.4776119402984,
      "grad_norm": 0.0007241975399665534,
      "learning_rate": 7.801772617738984e-07,
      "loss": 0.0,
      "step": 9580
    },
    {
      "epoch": 1066.7164179104477,
      "grad_norm": 0.0006482102908194065,
      "learning_rate": 7.55086357449998e-07,
      "loss": 0.0,
      "step": 9600
    },
    {
      "epoch": 1068.955223880597,
      "grad_norm": 0.000998330069705844,
      "learning_rate": 7.303929748148058e-07,
      "loss": 0.0,
      "step": 9620
    },
    {
      "epoch": 1071.1194029850747,
      "grad_norm": 0.0003312523476779461,
      "learning_rate": 7.060979496475814e-07,
      "loss": 0.0,
      "step": 9640
    },
    {
      "epoch": 1073.358208955224,
      "grad_norm": 0.00046010606456547976,
      "learning_rate": 6.82202104244653e-07,
      "loss": 0.0,
      "step": 9660
    },
    {
      "epoch": 1075.597014925373,
      "grad_norm": 0.00046529047540389,
      "learning_rate": 6.587062473916065e-07,
      "loss": 0.0,
      "step": 9680
    },
    {
      "epoch": 1077.8358208955224,
      "grad_norm": 0.00027932270313613117,
      "learning_rate": 6.356111743358942e-07,
      "loss": 0.0,
      "step": 9700
    },
    {
      "epoch": 1080.0,
      "grad_norm": 0.000911390408873558,
      "learning_rate": 6.129176667599351e-07,
      "loss": 0.0,
      "step": 9720
    },
    {
      "epoch": 1082.2388059701493,
      "grad_norm": 0.00030720848008058965,
      "learning_rate": 5.906264927546381e-07,
      "loss": 0.0,
      "step": 9740
    },
    {
      "epoch": 1084.4776119402984,
      "grad_norm": 0.00044491668813861907,
      "learning_rate": 5.687384067934217e-07,
      "loss": 0.0,
      "step": 9760
    },
    {
      "epoch": 1086.7164179104477,
      "grad_norm": 0.00038152531487867236,
      "learning_rate": 5.472541497066747e-07,
      "loss": 0.0,
      "step": 9780
    },
    {
      "epoch": 1088.955223880597,
      "grad_norm": 0.0004894045414403081,
      "learning_rate": 5.261744486566689e-07,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 1091.1194029850747,
      "grad_norm": 0.0004879624757450074,
      "learning_rate": 5.05500017112967e-07,
      "loss": 0.0,
      "step": 9820
    },
    {
      "epoch": 1093.358208955224,
      "grad_norm": 0.00041524256812408566,
      "learning_rate": 4.85231554828261e-07,
      "loss": 0.0,
      "step": 9840
    },
    {
      "epoch": 1095.597014925373,
      "grad_norm": 0.0006506337085738778,
      "learning_rate": 4.6536974781469236e-07,
      "loss": 0.0,
      "step": 9860
    },
    {
      "epoch": 1097.8358208955224,
      "grad_norm": 0.0008860894595272839,
      "learning_rate": 4.459152683206305e-07,
      "loss": 0.0,
      "step": 9880
    },
    {
      "epoch": 1100.0,
      "grad_norm": 0.00047503478708676994,
      "learning_rate": 4.268687748079217e-07,
      "loss": 0.0,
      "step": 9900
    },
    {
      "epoch": 1102.2388059701493,
      "grad_norm": 0.0004980692756362259,
      "learning_rate": 4.0823091192961074e-07,
      "loss": 0.0,
      "step": 9920
    },
    {
      "epoch": 1104.4776119402984,
      "grad_norm": 0.0006103769410401583,
      "learning_rate": 3.900023105081016e-07,
      "loss": 0.0,
      "step": 9940
    },
    {
      "epoch": 1106.7164179104477,
      "grad_norm": 0.0006810112972743809,
      "learning_rate": 3.721835875138274e-07,
      "loss": 0.0,
      "step": 9960
    },
    {
      "epoch": 1108.955223880597,
      "grad_norm": 0.0004079114005435258,
      "learning_rate": 3.5477534604435314e-07,
      "loss": 0.0,
      "step": 9980
    },
    {
      "epoch": 1111.1194029850747,
      "grad_norm": 0.000511492951773107,
      "learning_rate": 3.377781753039752e-07,
      "loss": 0.0,
      "step": 10000
    },
    {
      "epoch": 1113.358208955224,
      "grad_norm": 0.0005818866193294525,
      "learning_rate": 3.211926505837695e-07,
      "loss": 0.0,
      "step": 10020
    },
    {
      "epoch": 1115.597014925373,
      "grad_norm": 0.0008749842527322471,
      "learning_rate": 3.050193332421236e-07,
      "loss": 0.0,
      "step": 10040
    },
    {
      "epoch": 1117.8358208955224,
      "grad_norm": 0.0006914294790476561,
      "learning_rate": 2.892587706857394e-07,
      "loss": 0.0,
      "step": 10060
    },
    {
      "epoch": 1120.0,
      "grad_norm": 0.0005206266650930047,
      "learning_rate": 2.739114963511008e-07,
      "loss": 0.0,
      "step": 10080
    },
    {
      "epoch": 1122.2388059701493,
      "grad_norm": 0.0004965924890711904,
      "learning_rate": 2.5897802968642e-07,
      "loss": 0.0,
      "step": 10100
    },
    {
      "epoch": 1124.4776119402984,
      "grad_norm": 0.00048721799976192415,
      "learning_rate": 2.444588761340599e-07,
      "loss": 0.0,
      "step": 10120
    },
    {
      "epoch": 1126.7164179104477,
      "grad_norm": 0.000303340086247772,
      "learning_rate": 2.3035452711342026e-07,
      "loss": 0.0,
      "step": 10140
    },
    {
      "epoch": 1128.955223880597,
      "grad_norm": 0.0006234518368728459,
      "learning_rate": 2.166654600043158e-07,
      "loss": 0.0,
      "step": 10160
    },
    {
      "epoch": 1131.1194029850747,
      "grad_norm": 0.0004649969341699034,
      "learning_rate": 2.033921381308007e-07,
      "loss": 0.0,
      "step": 10180
    },
    {
      "epoch": 1133.358208955224,
      "grad_norm": 0.0005483553977683187,
      "learning_rate": 1.9053501074550868e-07,
      "loss": 0.0,
      "step": 10200
    },
    {
      "epoch": 1135.597014925373,
      "grad_norm": 0.0005340600037015975,
      "learning_rate": 1.7809451301442763e-07,
      "loss": 0.0,
      "step": 10220
    },
    {
      "epoch": 1137.8358208955224,
      "grad_norm": 0.000434061890700832,
      "learning_rate": 1.6607106600218387e-07,
      "loss": 0.0,
      "step": 10240
    },
    {
      "epoch": 1140.0,
      "grad_norm": 0.0010770680382847786,
      "learning_rate": 1.5446507665778793e-07,
      "loss": 0.0,
      "step": 10260
    },
    {
      "epoch": 1142.2388059701493,
      "grad_norm": 0.00037581706419587135,
      "learning_rate": 1.4327693780085277e-07,
      "loss": 0.0,
      "step": 10280
    },
    {
      "epoch": 1144.4776119402984,
      "grad_norm": 0.0006388649344444275,
      "learning_rate": 1.3250702810831546e-07,
      "loss": 0.0,
      "step": 10300
    },
    {
      "epoch": 1146.7164179104477,
      "grad_norm": 0.0004734524409286678,
      "learning_rate": 1.221557121015987e-07,
      "loss": 0.0,
      "step": 10320
    },
    {
      "epoch": 1148.955223880597,
      "grad_norm": 0.00029536455986090004,
      "learning_rate": 1.1222334013429036e-07,
      "loss": 0.0,
      "step": 10340
    },
    {
      "epoch": 1151.1194029850747,
      "grad_norm": 0.0002960587735287845,
      "learning_rate": 1.0271024838027914e-07,
      "loss": 0.0,
      "step": 10360
    },
    {
      "epoch": 1153.358208955224,
      "grad_norm": 0.0005292481509968638,
      "learning_rate": 9.361675882237353e-08,
      "loss": 0.0,
      "step": 10380
    },
    {
      "epoch": 1155.597014925373,
      "grad_norm": 0.0006083903135731816,
      "learning_rate": 8.494317924140904e-08,
      "loss": 0.0,
      "step": 10400
    },
    {
      "epoch": 1157.8358208955224,
      "grad_norm": 0.0005550977075472474,
      "learning_rate": 7.668980320582746e-08,
      "loss": 0.0,
      "step": 10420
    },
    {
      "epoch": 1160.0,
      "grad_norm": 0.0010076586622744799,
      "learning_rate": 6.885691006174449e-08,
      "loss": 0.0,
      "step": 10440
    },
    {
      "epoch": 1162.2388059701493,
      "grad_norm": 0.0007792427204549313,
      "learning_rate": 6.144476492348644e-08,
      "loss": 0.0,
      "step": 10460
    },
    {
      "epoch": 1164.4776119402984,
      "grad_norm": 0.0006303521804511547,
      "learning_rate": 5.445361866462939e-08,
      "loss": 0.0,
      "step": 10480
    },
    {
      "epoch": 1166.7164179104477,
      "grad_norm": 0.0008232410182245076,
      "learning_rate": 4.7883707909497646e-08,
      "loss": 0.0,
      "step": 10500
    }
  ],
  "logging_steps": 20,
  "max_steps": 10800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1200,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0191816015426355e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
