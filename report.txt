=== process_transcript ===

=== DOCS instructions.txt ===

DESIRED_OUTPUT gives the file in the files directory.


A new python file will be created where all \n are be replaced by a special character.
then all whitespace is replaced by a single space ' '
all punctuation characters are removed
all words become lower case


DESIRED_OUTPUT has 'formatted.txt' as part of the file name.

this part is replaced by '.txt'  -- alicewarrenformatted.txt becomes alicewarren.txt

the ouput is written to the new file name.

=== PY config.py ===
# Chunk processing configuration
CHUNK_OVERLAP = 75                # Increased overlap for smoother transitions
OUTPUT_CHUNK_SIZE = 125           # Adjusted output size

# Text processing parameters
SENTENCE_MARKER = chr(0x0a)       # Unicode character for boundaries

# File paths (unchanged)
SAVEDCHUNKS = 'files/savedchunks'
INPUT_FILE = 'files/transcript.txt'
CLEANED_FILE = 'files/transcript_preprocessed.txt'
PROCESSED_FILE = 'files/transcript_processed.txt'
POSTPROCESSED_FILE = 'files/transcript_postprocessed.txt'
OUTPUT_FILE = 'files/transcript_formatted.txt'
TEST_INPUT = 'files/testintput.txt'
TEST_OUTPUT = 'files/testoutput.txt'

# API configuration
API_URL = "http://0.0.0.0:5000/v1/completions"
API_TIMEOUT = 120                 # Increased timeout
MAX_TOKENS = 800                  # Increased token limit
# EXPANDED STOP_SEQUENCES to prevent LLM injecting unwanted instructional text
STOP_SEQUENCES = [
    "\n\n", "###", "##", "</end>", "Text:", "Formatted text:",
    "the formatted output should follow these guidelines",
    "each complete sentence must start on a new line",
    "proper nouns like alice are capitalized",
    "punctuation marks such as periods commas question marks exclamation points",
    "quoted material longer than four lines should be indented"
]

# Language model parameters
REPETITION_PENALTY = 1.2          # Balanced repetition control
TEMPERATURE = 0.15                # Lower temperature for consistency
TOP_P = 0.9                       # Focused sampling
TOP_K = 50                        # Balanced predictability
TOP_T = TOP_K # Retained TOP_T = TOP_K as it was in your original config. If your API doesn't use it, it will be ignored.

# Validation and logging
MAX_SENTENCE_VALIDATION_ERRORS = 3  # Stricter validation
LOG_DIR = 'logs'
LOG_FILE = 'runlog.log'
DEBUG_LOG_FILE = 'debug.log'

# Special processing flags
PRESERVE_CASE = True              # Maintain original capitalization
STRICT_PUNCTUATION = True         # Enforce proper punctuation
PRESERVE_PARAGRAPHS = True        # Maintain paragraph structure


# Quality control
MIN_SENTENCE_QUALITY = 0.8        
MAX_RETRIES = 3                   
#TEST_MODE = "run"
#TEST_MODE = "unformatted"
TEST_MODE = "desiredoutput"
TEST_FILE = 'files/alicewarren.txt'
DESIRED_OUTPUT = 'alicewarrenformatted.txt'
TRAINING_FILE = 'files/trainingchunks.txt'


__all__ = [
    'CHUNK_SIZE', 'CHUNK_OVERLAP', 'OUTPUT_CHUNK_SIZE', 'POSTPROCESSED_FILE',
    'SENTENCE_MARKER', 'INPUT_FILE', 'CLEANED_FILE', 'PROCESSED_FILE', 
    'OUTPUT_FILE', 'API_URL', 'API_TIMEOUT', 'MAX_TOKENS', 'STOP_SEQUENCES',
    'REPETITION_PENALTY', 'TEMPERATURE', 'TOP_P', 'TOP_K', 'TOP_T',
    'MAX_SENTENCE_VALIDATION_ERRORS', 'LOG_DIR', 'LOG_FILE',
    'DEBUG_LOG_FILE', 'PRESERVE_CASE', "TEST_OUTPUT", "DESIRED_OUTPUT"
    'STRICT_PUNCTUATION', 'PRESERVE_PARAGRAPHS', 'TRAINING_FILE',
    'MIN_SENTENCE_QUALITY', 'MAX_RETRIES', 'TEST_MODE'
]

=== PY logger.py ===
import logging
import os
from pathlib import Path
from config import LOG_DIR, LOG_FILE

def configure_logging():
    if logging.getLogger().hasHandlers():
        return
    os.makedirs(LOG_DIR, exist_ok=True)
    log_path = Path(LOG_DIR) / LOG_FILE
    if log_path.exists():
        log_path.unlink()
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_path),
            logging.StreamHandler()
        ]
    )

=== PY process.py ===
import os
import re
import logging
from logger import configure_logging
import textwrap
import aiohttp
import asyncio
import json
from config import (
    API_URL, API_TIMEOUT, MAX_TOKENS, STOP_SEQUENCES, TEST_MODE,
    REPETITION_PENALTY, TEMPERATURE, TOP_P, TOP_T, SENTENCE_MARKER,
    CHUNK_OVERLAP, OUTPUT_CHUNK_SIZE, TEST_INPUT, TEST_OUTPUT, DESIRED_OUTPUT,
    PROCESSED_FILE, POSTPROCESSED_FILE, TEST_FILE, TRAINING_FILE
)

class ParseFile:
    def __init__(self):
        self.input_string = ""
        self.chunk = ""
        self.output_string = ""
        self._cleaned = False
        self.api_url = API_URL
        self.logger = logging.getLogger(__name__)
        self.session = None
        self.input_array = []

    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    def loadchunk(self, word_count):
        words_loaded = 0
        words = []
        while words_loaded < word_count and self.input_word_pointer < len(self.input_array):
            words.append(self.input_array[self.input_word_pointer])
            self.input_word_pointer += 1
            words_loaded += 1

        wordschunk = ' '.join(words)
        self.chunk = (self.chunk + ' ' + wordschunk).strip()  # Ensure space between chunks
        self.logger.info(f'Loaded {words_loaded} words (input pointer: {self.input_word_pointer})')
        return self.chunk
    
    async def formatchunk(self, chunktext: str) -> str:
        if self.session is None:
            self.session = aiohttp.ClientSession()
        
        prompt = textwrap.dedent(f"""\
            Your task is to reformat the provided text.
            Strictly adhere to the following rules:
            - Maintain the EXACT original words and their order.
            - NEVER add, delete, rephrase, or summarize any words.
            - Put each complete sentence on its own line.
            - Do NOT merge sentences together.
            - Do NOT let proper names end sentences if they are part of an ongoing thought.
            - Add proper punctuation (periods, question marks, exclamation points) to complete sentences only at their end.
            - Capitalize the first word of each complete sentence.
            - Leave incomplete fragments as-is on their own line.
            - ONLY output the reformatted text. DO NOT include any additional commentary, explanations, or instructions.
            - Ensure there are no extra spaces before or after any punctuation mark.

            Example:
            Input: "the cat sat the dog ran"
            Output: "The cat sat.\nThe dog ran."

            Text: {chunktext}

            Formatted text:""")

        try:
            async with self.session.post(
                API_URL,
                json={
                    "prompt": prompt,
                    "max_tokens": MAX_TOKENS,
                    "temperature": TEMPERATURE,
                    "stop": STOP_SEQUENCES,
                    "repetition_penalty": REPETITION_PENALTY,
                    "top_p": TOP_P,
                    "top_t": TOP_T
                },
                timeout=aiohttp.ClientTimeout(total=API_TIMEOUT)
            ) as response:
                if response.status != 200:
                    error_message = f"API returned non-200 status: {response.status}. Response: {await response.text()}"
                    self.logger.error(error_message)
                    return chunktext
                
                result = await response.json()
                formatted = result.get("choices", [{}])[0].get("text", "").strip()
                return formatted if formatted else chunktext
                
        except Exception as e:
            self.logger.error(f"Error formatting chunk: {str(e)}")
            return chunktext

    def deformat(self, formatted_output):
        protected = formatted_output.replace('\n', SENTENCE_MARKER)
        output = protected.lower()
        output = re.sub(f'[^a-z\\s{re.escape(SENTENCE_MARKER)}]', '', output)
        return output.replace(SENTENCE_MARKER, ' ')

    def preprocess(self, input_file):
        self.input_file = input_file
        self.logger.debug(f'Preprocessing: {self.input_file}')
        try:
            with open(self.input_file, 'r', encoding='utf-8') as f:
                text = f.read()

            text = text.lower()
            text = text.replace("'", "'").replace('"', '"')
            text = text.replace("—", " -- ")
            text = re.sub(r"[^a-z0-9'\-\s]", " ", text)
            text = re.sub(r'\s+', ' ', text).strip()

            words = [word for word in text.split(' ') if word]
            cleaned_text = ' '.join(words)
            self.input_string = cleaned_text
            self.input_array = words
            self.textsize = len(cleaned_text)
            return cleaned_text

        except Exception as e:
            self.logger.error(f'Preprocessing failed: {e}', exc_info=True)
            raise

    def getdesiredchunk(self, text):
        try:
            # Preserve trailing whitespace but remove leading whitespace
            stripped_text = text.lstrip()
            trailing_whitespace = text[len(stripped_text.rstrip()):] if text.rstrip() != text else ''
            
            target_words = stripped_text.split()
            num_words = len(target_words)

            input_words = self.deformat(self.input_string).strip().split()
            for i in range(len(input_words) - num_words + 1):
                if input_words[i:i + num_words] == target_words:
                    start_word_index = i
                    break
            else:
                raise ValueError("Chunk not found in input_string.")

            with open(os.path.join("files", DESIRED_OUTPUT), "r", encoding='utf-8') as f:
                desired_content = f.read()
                lines = desired_content.split('\n')

            word_locations = []
            for line_index, line in enumerate(lines):
                words_in_line = line.strip().split()
                for word_index, word in enumerate(words_in_line):
                    word_locations.append((line_index, word_index))

            if start_word_index + num_words > len(word_locations):
                raise ValueError("Chunk exceeds length of desired output.")

            chunk_locations = word_locations[start_word_index:start_word_index + num_words]
            line_buffer = {}
            for line_index, word_index in chunk_locations:
                original_line = lines[line_index]
                words_in_line = original_line.strip().split()
                word = words_in_line[word_index]
                
                if line_index not in line_buffer:
                    line_buffer[line_index] = {'words': [], 'line_end': original_line.endswith(('.', '?', '!'))}
                line_buffer[line_index]['words'].append(word)

            # Reconstruct lines with original punctuation
            ordered_lines = []
            for line_index in sorted(line_buffer):
                line_data = line_buffer[line_index]
                reconstructed_line = ' '.join(line_data['words'])
                if line_data['line_end'] and not reconstructed_line.endswith(('.', '?', '!')):
                    reconstructed_line += '.'
                ordered_lines.append(reconstructed_line)

            desired_chunk = '\n'.join(ordered_lines) + trailing_whitespace
            
            return desired_chunk

        except Exception as e:
            self.logger.error(f'getdesiredchunk failed: {e}', exc_info=True)
            return text

    def generateIOpair(self, chunk, formatted):
        command = "Punctuate sentences."
        input_text = chunk
        
        # Ensure we're working with the properly formatted text from desired_output.txt
        formatted = self.getdesiredchunk(self.deformat(formatted))
        
        # Properly escape newlines and ensure consistent formatting
        output_text = formatted.replace('\n', '\n')
        
        # Create the new entry with consistent formatting
        entry = {
            "instruction": command,
            "input": input_text,
            "output": output_text
        }

        # Convert to compact JSON string on one line
        json_str = json.dumps(entry, ensure_ascii=False, separators=(', ', ': '))
        
        # Check for existing content to avoid duplicates
        existing_content = []
        if os.path.exists(TRAINING_FILE):
            with open(TRAINING_FILE, 'r', encoding='utf-8') as f:
                existing_content = [line.strip() for line in f.readlines() if line.strip()]
        
        # Only write if this exact entry doesn't exist
        if json_str not in existing_content:
            with open(TRAINING_FILE, 'a', encoding='utf-8') as f:
                f.write(json_str + '\n')

    async def format(self, text):
        formatted = ""
        chunk = self.deformat(text)
        match TEST_MODE:
            case "unformatted":
                formatted = chunk
            case "desiredoutput":
                formatted = self.getdesiredchunk(chunk)
                self.generateIOpair(chunk, formatted)
            case "run":
                formatted = await self.formatchunk(chunk)
            case _:
                formatted = chunk
        return formatted
    
    def find_first_mismatch(self, str1, str2):
        min_len = min(len(str1), len(str2))
        for i in range(min_len):
            if str1[i] != str2[i]:
                return f"Mismatch at index {i}: '{str1[i]}' != '{str2[i]}'"
        if len(str1) != len(str2):
            return f"Mismatch at index {min_len}: One string is longer"
        return "Strings are identical"

    def split_into_two_chunks(self, text, n):
        """Improved version that preserves word boundaries and spacing"""
        if not text.strip():
            return "", ""
            
        words = re.findall(r'\S+\s*', text)  # Preserve original spacing
        if n >= len(words):
            return text, ""
            
        first_part = ''.join(words[:n])
        second_part = ''.join(words[n:])
        
        if not first_part.endswith((' ', '\n')) and not second_part.startswith((' ', '\n')):
            first_part += ' '
            
        return first_part.rstrip(), second_part

    async def process(self, input_file: str):
        self.input_string = self.preprocess(input_file)
        self.cleanedinput_file = PROCESSED_FILE
        self.output_file = POSTPROCESSED_FILE
            
        try:
            input_string = self.input_string
            output_string = ""
            context_window = ""
            chunk_size = OUTPUT_CHUNK_SIZE
            overlap_size = CHUNK_OVERLAP
            total_chunk_size = chunk_size + overlap_size
                
            first_chunk, remaining_input = self.split_into_two_chunks(input_string, total_chunk_size)
            context_window = await self.format(first_chunk)
                
            while remaining_input.strip():
                output_part, overlap_part = self.split_into_two_chunks(context_window, chunk_size)
                
                if output_string and not output_string.endswith((' ', '\n')):
                    output_string += ' '
                output_string += output_part
                
                next_chunk, remaining_input = self.split_into_two_chunks(
                    remaining_input, 
                    chunk_size - overlap_size
                )
                
                if not next_chunk.strip() and not remaining_input.strip():
                    break
                
                combined = overlap_part
                if combined and next_chunk:
                    if not combined.endswith((' ', '\n')) and not next_chunk.startswith((' ', '\n')):
                        combined += ' '
                combined += next_chunk
                
                context_window = await self.format(combined)

            if output_string and not output_string.endswith((' ', '\n')):
                output_string += ' '
            output_string += context_window

            
            with open(TEST_INPUT, "w", encoding='utf-8') as f:
                f.write(self.input_string)

            with open(TEST_OUTPUT, "w", encoding='utf-8') as f:
                f.write(output_string.strip())

            if TEST_MODE == "unformatted":
                with open(os.path.join("files", DESIRED_OUTPUT), "r", encoding='utf-8') as f:
                    desiredcontent = f.read()
                result = self.find_first_mismatch(desiredcontent, output_string)
                print(result)

            if TEST_MODE == "desiredoutput":
                with open(os.path.join("files", DESIRED_OUTPUT), "r", encoding='utf-8') as f:
                    desiredcontent = f.read()
                result = self.find_first_mismatch(desiredcontent, output_string)
                print(result)

            return output_string.strip()

        except Exception as e:
            self.logger.error(f'Processing failed: {e}', exc_info=True)
            raise

async def main():
    configure_logging()
    logger = logging.getLogger('main')
    try:
        async with ParseFile() as parser:
            await parser.process(TEST_FILE)
        logger.info("Processing completed successfully")
    except Exception as e:
        logger.error(f"Processing failed: {str(e)}", exc_info=True)
        raise

if __name__ == "__main__":
    asyncio.run(main())

=== PY testoutput.txt ===
Alice Warren sat beside a wide window in the corner of her study.
The late afternoon light slanted gently across the hardwood floor, illuminating endless rows of books that lined the walls.
She loved the hush of quiet contemplation, the soft rustle of turning pages, and the subtle comfort of stories held within paper and ink.
It was in this exact space that she found solace after a long day of meetings, presentations, and endless email chains.
The silence was not merely an absence of noise; it was a presence in itself, a companion that whispered in comfortable tones and allowed thoughts to drift unencumbered.
Outside, the garden lay in gentle bloom.
Roses of deep crimson and pale pink nodded in the early breeze, while lavender and thyme filled the afternoon air with fragrant sweetness.
A pair of robins hopped atop the low stone wall, pecking at small insects among the wild clover.
Occasionally, a butterfly orange with black veined wings fluttered past the aging glass, and Alice followed its slow, drifting flight for a moment before returning to her book.
Such ordinary spectacles, when observed with attention, held a profound beauty.
It was a lesson she had learned, early and often: that the marvels of life are seldom grand or flashy; they are small, quiet, and easily overlooked.
Her book, an anthology of short stories from the early twentieth century, lay open on her lap.
The paper was slightly yellowed, but sturdy; the ink, crisp.
Each story contained within. had been selected for its faithful representation of time, place, and character.
There was a certain charm in the way authors of that era wove descriptive passages around otherwise trivial actions tying shoelaces, pouring tea, gazing out toward a stormy horizon.
Such attentiveness to detail formed a tapestry of everyday. life, and it fascinated Alice how these small gestures could reveal so much about an individual’s hopes, fears, and inner world.
In one story, a young woman stood at the edge of a river, watching the current drift by as though it carried with it unspoken promises of a distant. future.
The description was simple: “She lifted her hands above her head, letting the cool, early spring wind play through her fingers.”
Yet that image carried emotion enough to fill a lifetime of longing.
Alice closed her eyes, imagining the wind on her skin, and for a moment, she felt. transported away from her study to that riverside scene.
Then she opened her eyes again, setting the bookmark between the pages, and raised her gaze to the window.
The sun had sunk lower; the sky had begun to shift to ethereal shades of lavender and gold.
Soon, the garden would. blur into silhouettes, and the air would cool.
She reached for the small porcelain teapot on the table beside her.
It held a fragrant chamomile infusion, with just a hint of honey.
Alice poured the steaming liquid into her favorite cup, the one painted with delicate blue forget‑me‑nots.
She paused. to inhale the warm steam, allowing its gentle scent to settle her mind. It had become something of a ritual, this tea drinking ritual, a momentary pause between the realms of thought and rest.
Turning back to her anthology, she selected a different story.
This one described an early morning. in a busy city: horse drawn carriages rattling over cobblestones, merchants hawking wares at street stalls, and the clamor of voices in unfamiliar tongues.
As she read, Alice imagined herself there: she could almost hear the clip clop of hooves and feel the rough stone underfoot, the weight of her. satchel on her shoulder.
Again, she closed her eyes, letting the sounds and textures swirl around her senses until she could scarcely distinguish them from her own reality.
Such was the power of fine writing it created an illusion so vivid, so grounded, that the line between reader and narrator. blurred.
By the time she finished the second story, darkness had fallen completely.
The study lamp cast a soft pool of light around her chair.
Beyond the window, the garden was now a shadowy realm, defined only by silhouettes and the glimmer of a single landing moth.
In the distance,. a lone streetlamp flickered to life; its orange glow rebounded off dewy leaves, turning them into luminous orbs.
Alice closed the anthology, pressed a finger against the spine, and slid the book into its place on the shelf.
She sat for a moment longer, teacup in hand, simply being.
It. was a practice in mindfulness, in appreciating transition.
The end of daylight and arrival of evening, the movement from narrative to reflection.
She allowed herself this small pause before rising to begin the next phase of her evening routine: preparing a light supper, writing a few thoughtful entries in her. journal, and perhaps stepping out onto the back porch to breathe beneath a sky of stars.
When she finally stood, the teacup empty, the anthology closed, and the quiet settled deeply over the room, Alice felt a gentle contentment.
Gratitude, even.
For the stories, yes and for the world beyond. them, for the tactile, living reality she inhabits.
And so, at the close of day, she gave thanks: for words, for solitude, and for the small wonders that attend each ordinary moment.

